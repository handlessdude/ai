{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Лаб-3. Рекомендательные системы"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T20:23:55.596460Z",
     "start_time": "2024-12-06T20:23:55.593269Z"
    }
   },
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "# Выбираем девайс\n",
    "USE_CUDA = False\n",
    "device = \"cuda\" if USE_CUDA and torch.cuda.is_available() else \"cpu\"\n",
    "print(f'Device: {device}')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n"
     ]
    }
   ],
   "execution_count": 202
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T20:23:55.666846Z",
     "start_time": "2024-12-06T20:23:55.615270Z"
    }
   },
   "source": [
    "OPTIMAL_TAGS_PER_PAIR_COUNT = 6\n",
    "# Для загрузки датасета напишем свою реализацию класса Dataset\n",
    "class MovielensDataset(Dataset):\n",
    "    r\"\"\"seed должен быть одинаковым для обучающей и тренировочной выборки\"\"\"\n",
    "    def __init__(self, source, train=True, seed=1, new_user_ratings=None, max_tags_per_pair=OPTIMAL_TAGS_PER_PAIR_COUNT):\n",
    "        self.max_tags_per_pair = max_tags_per_pair\n",
    "        ratings      = pd.read_csv(rf\"{source}/ratings.csv\")\n",
    "        self.movies  = pd.read_csv(rf\"{source}/movies.csv\")\n",
    "        self.tags = pd.read_csv(rf\"{source}/tags.csv\")\n",
    "        \n",
    "        # Преобразовываем Id фильмов в индексы в таблице movies\n",
    "        # x = self.movies.loc[:,['movieId']]\n",
    "        # x['movieId'], x.index = x.index, x['movieId'].values\n",
    "        # ratings['movieId'] = ratings['movieId'].map(x.to_dict()['movieId'])\n",
    "        \n",
    "        movie_id_map = pd.Series(self.movies.index, index=self.movies['movieId']).to_dict()\n",
    "        ratings['movieId'] = ratings['movieId'].map(movie_id_map)\n",
    "        \n",
    "        self.tag_id_map = {\n",
    "            tag: idx\n",
    "            for idx, tag in enumerate(self.tags['tag'].unique())\n",
    "        }\n",
    "        self.tags['movieId'] = self.tags['movieId'].map(movie_id_map)\n",
    "        self.tags['tagId'] = self.tags['tag'].map(self.tag_id_map)\n",
    "        print(self.tags)\n",
    "        \n",
    "        if new_user_ratings:\n",
    "            new_user_id = ratings['userId'].max() + 1\n",
    "            new_ratings = pd.DataFrame([\n",
    "                {\n",
    "                    'userId': new_user_id,\n",
    "                    'movieId': movie_idx,\n",
    "                    'rating': rating\n",
    "                } for movie_idx, rating in new_user_ratings\n",
    "            ])\n",
    "            ratings = pd.concat([ratings, new_ratings], ignore_index=True)\n",
    "\n",
    "        # делим датасет 80% на 20%\n",
    "        train_data = ratings.sample(frac=0.8, random_state=seed)\n",
    "        test_data  = ratings.drop(train_data.index)\n",
    "\n",
    "        self.ratings = train_data if train else test_data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ratings)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.ratings.iloc[idx]\n",
    "        user, movie = sample['userId'], sample['movieId']\n",
    "        tag_ids = self.tags[(self.tags['userId'] == user) & (self.tags['movieId'] == movie)]['tagId'].tolist()\n",
    "        \n",
    "        # pad/truncate tag_ids to fixed size\n",
    "        if len(tag_ids) < self.max_tags_per_pair:\n",
    "            tag_ids += [0] * (self.max_tags_per_pair - len(tag_ids))\n",
    "        else:\n",
    "            tag_ids = tag_ids[:self.max_tags_per_pair] \n",
    "        \n",
    "        return {\n",
    "            \"user\": torch.LongTensor([user]),\n",
    "            \"movie\": torch.LongTensor([movie]),\n",
    "            \"rating\": torch.FloatTensor([sample['rating']]),\n",
    "            \"tags\": torch.LongTensor(tag_ids)\n",
    "        }\n",
    "\n",
    "def generate_random_ratings(num_movies, num_ratings=20):\n",
    "    random_movies = random.sample(range(num_movies), num_ratings)\n",
    "    ratings = [(movie_idx, random.uniform(1, 5)) for movie_idx in random_movies]\n",
    "    return ratings\n",
    "\n",
    "def suggest_movies(model, user_id, movies_df, suggestions_count=10):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        all_movie_ids = torch.arange(len(movies_df), dtype=torch.long).to(device)\n",
    "        user_tensor = torch.LongTensor([user_id] * len(all_movie_ids)).to(device)\n",
    "        predictions = model({\n",
    "            \"user\": user_tensor.unsqueeze(1),\n",
    "            \"movie\": all_movie_ids.unsqueeze(1)\n",
    "        })\n",
    "        predictions = predictions.squeeze(1)\n",
    "        recommended_ids = predictions.argsort(descending=True)[:suggestions_count]\n",
    "        return movies_df.iloc[recommended_ids.cpu().numpy()]"
   ],
   "outputs": [],
   "execution_count": 203
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T20:23:55.913765Z",
     "start_time": "2024-12-06T20:23:55.667576Z"
    }
   },
   "source": [
    "BATCH_SIZE = 200\n",
    "DATASET_SOURCE = r'./data'\n",
    "MOCK_RATINGS_COUNT = 20\n",
    "\n",
    "mock_ratings = generate_random_ratings(MOCK_RATINGS_COUNT)\n",
    "RATINGS = [\n",
    "    (111, 5.0), # 111,Taxi Driver (1976),Crime|Drama|Thriller\n",
    "    (55444, 4.5), # 55444,Control (2007),Drama\n",
    "    (88129, 5.0), # 88129,Drive (2011),Crime|Drama|Film-Noir|Thriller\n",
    "    (99114, 5.0), # 99114,Django Unchained (2012),Action|Drama|Western\n",
    "    (27156, 4.5), # 27156,\"Neon Genesis Evangelion: The End of Evangelion (Shin seiki Evangelion Gekijô-ban: Air/Magokoro wo, kimi ni) (1997)\",Action|Animation|Drama|Fantasy|Sci-Fi\n",
    "    (47423, 4.0), # 47423,Half Nelson (2006),Drama\n",
    "    (4306, 5.0), # 4306,Shrek (2001),Adventure|Animation|Children|Comedy|Fantasy|Romance\n",
    "    (8360, 5.0), # 8360,Shrek 2 (2004),Adventure|Animation|Children|Comedy|Musical|Romance\n",
    "    (53121, 5.0), # 53121,Shrek the Third (2007),Adventure|Animation|Children|Comedy|Fantasy\n",
    "    (541, 5.0), # 541,Blade Runner (1982),Action|Sci-Fi|Thriller\n",
    "    (122886,2.0), # 122886,Star Wars: Episode VII - The Force Awakens (2015),Action|Adventure|Fantasy|Sci-Fi|IMAX\n",
    "    (5444, 5.0), # 5444,Lilo & Stitch (2002),Adventure|Animation|Children|Sci-Fi\n",
    "    (171749, 4.0), # 171749,Death Note: Desu nôto (2006–2007),(no genres listed)\n",
    "    (47, 4.5), # 47,Seven (a.k.a. Se7en) (1995),Mystery|Thriller\n",
    "    (1201, 5.0), # 1201,\"Good, the Bad and the Ugly, The (Buono, il brutto, il cattivo, Il) (1966)\",Action|Adventure|Western\n",
    "    (2951, 5.0), # 2951,\"Fistful of Dollars, A (Per un pugno di dollari) (1964)\",Action|Western\n",
    "    (64614, 5.0), # 64614,Gran Torino (2008),Crime|Drama\n",
    "    (72737, 5.0), # 72737,\"Princess and the Frog, The (2009)\",Animation|Children|Fantasy|Musical|Romance\n",
    "    (101525, 3.5), # 101525,\"Place Beyond the Pines, The (2012)\",Crime|Drama\n",
    "    (31658, 5.0), # 31658,Howl's Moving Castle (Hauru no ugoku shiro) (2004),Adventure|Animation|Fantasy|Romance\n",
    "]\n",
    "\n",
    "movielens_train = MovielensDataset(DATASET_SOURCE, train=True, new_user_ratings=mock_ratings)\n",
    "movielens_test  = MovielensDataset(DATASET_SOURCE, train=False)\n",
    "\n",
    "train_loader = DataLoader(movielens_train, BATCH_SIZE, True)\n",
    "test_loader = DataLoader(movielens_test, BATCH_SIZE, True)\n",
    "\n",
    "for batch in train_loader:\n",
    "    for k, v in batch.items():\n",
    "        print(k, v.shape)\n",
    "    break"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      userId  movieId               tag   timestamp  tagId\n",
      "0          2     6801             funny  1445714994      0\n",
      "1          2     6801   Highly quotable  1445714996      1\n",
      "2          2     6801      will ferrell  1445714992      2\n",
      "3          2     7697      Boxing story  1445715207      3\n",
      "4          2     7697               MMA  1445715200      4\n",
      "...      ...      ...               ...         ...    ...\n",
      "3678     606     4925         for katie  1171234019   1584\n",
      "3679     606     5062           austere  1173392334   1585\n",
      "3680     610     2452            gun fu  1493843984   1586\n",
      "3681     610     2452  heroic bloodshed  1493843978   1587\n",
      "3682     610     9461  Heroic Bloodshed  1493844270   1588\n",
      "\n",
      "[3683 rows x 5 columns]\n",
      "      userId  movieId               tag   timestamp  tagId\n",
      "0          2     6801             funny  1445714994      0\n",
      "1          2     6801   Highly quotable  1445714996      1\n",
      "2          2     6801      will ferrell  1445714992      2\n",
      "3          2     7697      Boxing story  1445715207      3\n",
      "4          2     7697               MMA  1445715200      4\n",
      "...      ...      ...               ...         ...    ...\n",
      "3678     606     4925         for katie  1171234019   1584\n",
      "3679     606     5062           austere  1173392334   1585\n",
      "3680     610     2452            gun fu  1493843984   1586\n",
      "3681     610     2452  heroic bloodshed  1493843978   1587\n",
      "3682     610     9461  Heroic Bloodshed  1493844270   1588\n",
      "\n",
      "[3683 rows x 5 columns]\n",
      "user torch.Size([200, 1])\n",
      "movie torch.Size([200, 1])\n",
      "rating torch.Size([200, 1])\n",
      "tags torch.Size([200, 6])\n"
     ]
    }
   ],
   "execution_count": 204
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T20:23:55.918532Z",
     "start_time": "2024-12-06T20:23:55.914522Z"
    }
   },
   "source": [
    "# Функции для обучения из прошлой лабы, с учётом юзеров и айтемов\n",
    "\n",
    "def train_iteration(model, data_loader, loss_function, optimizer):\n",
    "    model.train()\n",
    "    train_size = len(data_loader.dataset)\n",
    "    for idx, batch in enumerate(data_loader):\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        pred = model(batch)\n",
    "        loss = loss_function(pred, batch['rating'])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        if idx % 100 == 0:\n",
    "            loss, current = loss.item(), (idx + 1) * BATCH_SIZE\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{train_size:>5d}]\")\n",
    "\n",
    "def test(model, data_loader, loss_function):\n",
    "    model.eval()\n",
    "    num_batches = len(data_loader)\n",
    "    loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader:\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            pred = model(batch)\n",
    "            loss += loss_function(pred, batch['rating']).item()\n",
    "\n",
    "    loss /= num_batches\n",
    "    print(f\"Avg loss: {loss:>8f} \\n\")\n",
    "\n",
    "\n",
    "def train(epochs, model, loss_function, optimizer):\n",
    "    for t in tqdm(range(epochs)):\n",
    "        print(f\"== Epoch {t + 1} ==\")\n",
    "        train_iteration(model, train_loader, loss_function, optimizer)\n",
    "        test(model, test_loader, loss_function)\n"
   ],
   "outputs": [],
   "execution_count": 205
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T20:23:56.006007Z",
     "start_time": "2024-12-06T20:23:55.919387Z"
    }
   },
   "cell_type": "code",
   "source": "sum([32,32])",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 206
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T20:29:11.630783Z",
     "start_time": "2024-12-06T20:23:56.006604Z"
    }
   },
   "source": [
    "class DeepFM(nn.Module):\n",
    "    def __init__(self, num_users=1000, num_movies=10000, num_tags=5000):\n",
    "        super().__init__()\n",
    "       \n",
    "        self.embeddings_dim = [32, 32, 16]\n",
    "        self.fm_dim = self.embeddings_dim[0]\n",
    "        \n",
    "        self.user_embeddings = nn.Embedding(num_users, self.embeddings_dim[0])\n",
    "        self.movie_embeddings = nn.Embedding(num_movies, self.embeddings_dim[1])\n",
    "        self.tag_embeddings = nn.Embedding(num_tags, self.embeddings_dim[2], padding_idx=0)\n",
    "\n",
    "        self.deep_input_dim = sum(self.embeddings_dim)\n",
    "        self.deep_linear_dim = 128\n",
    "        self.deep_output_dim = 128\n",
    "        \n",
    "        self.flatten = nn.Flatten()\n",
    "        self.deep_layers = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(self.deep_input_dim, self.deep_linear_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(self.deep_linear_dim, self.deep_linear_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.6),\n",
    "            nn.Linear(self.deep_linear_dim, self.deep_output_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.7),\n",
    "        )\n",
    "\n",
    "        self.final_layer = nn.Linear(self.deep_output_dim + self.fm_dim, 1)  # adjusted input size\n",
    "\n",
    "    def forward(self, batch):\n",
    "        movie_emb = self.flatten(self.user_embeddings(batch['user']))\n",
    "        user_emb = self.flatten(self.movie_embeddings(batch['movie']))\n",
    "\n",
    "        # Compute mean of tag embeddings while ignoring padding (0)\n",
    "        tag_emb = self.tag_embeddings(batch['tags'])  # Shape: [batch_size, max_tags_per_pair, tag_embedding_dim]\n",
    "        mask = (batch['tags'] != 0).float().unsqueeze(2)  # Shape: [batch_size, max_tags_per_pair, 1] (.unsqueeze(2) adds an extra dimension to make the mask compatible with tag_emb)\n",
    "        tag_emb = (tag_emb * mask).sum(dim=1) / mask.sum(dim=1).clamp(min=1)  # Avoid division by 0\n",
    "        \n",
    "        fm = movie_emb * user_emb\n",
    "\n",
    "        deep = torch.cat([movie_emb, user_emb, tag_emb], 1)\n",
    "        deep = self.deep_layers(deep)\n",
    "\n",
    "        v = torch.cat([fm, deep], 1)\n",
    "        v = self.final_layer(v)\n",
    "        # делаем сигмоиду на выходе и масштабируем к оценкам от 0 до 5\n",
    "        return torch.sigmoid(v) * 5\n",
    "\n",
    "EPOCHS_COUNT = 12\n",
    "LEARNING_RATE = 1e-3\n",
    "\n",
    "deep_mf_model = DeepFM(\n",
    "    num_users=movielens_train.ratings['userId'].max() + 1,\n",
    "    num_movies=len(movielens_train.movies),\n",
    "    num_tags=len(movielens_train.tag_id_map)\n",
    ").to(device)\n",
    "\n",
    "deep_mf_loss = nn.MSELoss()\n",
    "deep_mf_optimizer = torch.optim.Adam(deep_mf_model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "train(EPOCHS_COUNT, deep_mf_model, deep_mf_loss, deep_mf_optimizer)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/12 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Epoch 1 ==\n",
      "loss: 2.092288  [  200/80685]\n",
      "loss: 0.748927  [20200/80685]\n",
      "loss: 1.108499  [40200/80685]\n",
      "loss: 1.081762  [60200/80685]\n",
      "loss: 1.114565  [80200/80685]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 1/12 [00:26<04:54, 26.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg loss: 0.991520 \n",
      "\n",
      "== Epoch 2 ==\n",
      "loss: 1.022522  [  200/80685]\n",
      "loss: 1.102782  [20200/80685]\n",
      "loss: 0.958003  [40200/80685]\n",
      "loss: 0.986364  [60200/80685]\n",
      "loss: 0.862795  [80200/80685]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 2/12 [00:54<04:30, 27.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg loss: 0.945812 \n",
      "\n",
      "== Epoch 3 ==\n",
      "loss: 1.029125  [  200/80685]\n",
      "loss: 0.864081  [20200/80685]\n",
      "loss: 0.905576  [40200/80685]\n",
      "loss: 0.876675  [60200/80685]\n",
      "loss: 0.899984  [80200/80685]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 3/12 [01:20<04:01, 26.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg loss: 0.911022 \n",
      "\n",
      "== Epoch 4 ==\n",
      "loss: 0.870327  [  200/80685]\n",
      "loss: 0.927729  [20200/80685]\n",
      "loss: 1.131358  [40200/80685]\n",
      "loss: 0.911318  [60200/80685]\n",
      "loss: 0.936722  [80200/80685]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 4/12 [01:46<03:31, 26.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg loss: 0.872763 \n",
      "\n",
      "== Epoch 5 ==\n",
      "loss: 1.008279  [  200/80685]\n",
      "loss: 0.869886  [20200/80685]\n",
      "loss: 0.872650  [40200/80685]\n",
      "loss: 0.718627  [60200/80685]\n",
      "loss: 0.949262  [80200/80685]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 5/12 [02:12<03:05, 26.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg loss: 0.861467 \n",
      "\n",
      "== Epoch 6 ==\n",
      "loss: 0.733753  [  200/80685]\n",
      "loss: 0.797536  [20200/80685]\n",
      "loss: 0.970638  [40200/80685]\n",
      "loss: 0.859867  [60200/80685]\n",
      "loss: 0.885158  [80200/80685]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 6/12 [02:39<02:38, 26.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg loss: 0.832403 \n",
      "\n",
      "== Epoch 7 ==\n",
      "loss: 0.790282  [  200/80685]\n",
      "loss: 0.816547  [20200/80685]\n",
      "loss: 0.852903  [40200/80685]\n",
      "loss: 0.940612  [60200/80685]\n",
      "loss: 0.740704  [80200/80685]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 7/12 [03:04<02:10, 26.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg loss: 0.832377 \n",
      "\n",
      "== Epoch 8 ==\n",
      "loss: 0.739345  [  200/80685]\n",
      "loss: 0.802607  [20200/80685]\n",
      "loss: 0.692684  [40200/80685]\n",
      "loss: 0.919207  [60200/80685]\n",
      "loss: 0.913751  [80200/80685]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 8/12 [03:30<01:44, 26.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg loss: 0.816618 \n",
      "\n",
      "== Epoch 9 ==\n",
      "loss: 0.761524  [  200/80685]\n",
      "loss: 0.861380  [20200/80685]\n",
      "loss: 0.920589  [40200/80685]\n",
      "loss: 0.732380  [60200/80685]\n",
      "loss: 0.700316  [80200/80685]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 9/12 [03:58<01:19, 26.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg loss: 0.801946 \n",
      "\n",
      "== Epoch 10 ==\n",
      "loss: 0.712858  [  200/80685]\n",
      "loss: 0.744364  [20200/80685]\n",
      "loss: 0.813577  [40200/80685]\n",
      "loss: 0.654197  [60200/80685]\n",
      "loss: 0.960116  [80200/80685]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 10/12 [04:24<00:52, 26.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg loss: 0.798297 \n",
      "\n",
      "== Epoch 11 ==\n",
      "loss: 0.710278  [  200/80685]\n",
      "loss: 0.842630  [20200/80685]\n",
      "loss: 0.620917  [40200/80685]\n",
      "loss: 0.767059  [60200/80685]\n",
      "loss: 0.937109  [80200/80685]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 11/12 [04:49<00:26, 26.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg loss: 0.808444 \n",
      "\n",
      "== Epoch 12 ==\n",
      "loss: 0.579433  [  200/80685]\n",
      "loss: 0.666241  [20200/80685]\n",
      "loss: 0.786733  [40200/80685]\n",
      "loss: 0.745399  [60200/80685]\n",
      "loss: 0.638515  [80200/80685]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [05:15<00:00, 26.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg loss: 0.789579 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 207
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T20:29:11.677688Z",
     "start_time": "2024-12-06T20:29:11.631510Z"
    }
   },
   "cell_type": "code",
   "source": [
    "SUGGESTIONS_COUNT = 20\n",
    "\n",
    "print(\"Movie Recommendations for me:\")\n",
    "new_user_id = movielens_train.ratings['userId'].max()\n",
    "suggestions = suggest_movies(deep_mf_model, new_user_id, movielens_train.movies, suggestions_count=SUGGESTIONS_COUNT)\n",
    "suggestions"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movie Recommendations for me:\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'tags'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[208], line 5\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mMovie Recommendations for me:\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m      4\u001B[0m new_user_id \u001B[38;5;241m=\u001B[39m movielens_train\u001B[38;5;241m.\u001B[39mratings[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124muserId\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mmax()\n\u001B[0;32m----> 5\u001B[0m suggestions \u001B[38;5;241m=\u001B[39m \u001B[43msuggest_movies\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdeep_mf_model\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnew_user_id\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmovielens_train\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmovies\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msuggestions_count\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mSUGGESTIONS_COUNT\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      6\u001B[0m suggestions\n",
      "Cell \u001B[0;32mIn[203], line 75\u001B[0m, in \u001B[0;36msuggest_movies\u001B[0;34m(model, user_id, movies_df, suggestions_count)\u001B[0m\n\u001B[1;32m     73\u001B[0m all_movie_ids \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39marange(\u001B[38;5;28mlen\u001B[39m(movies_df), dtype\u001B[38;5;241m=\u001B[39mtorch\u001B[38;5;241m.\u001B[39mlong)\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[1;32m     74\u001B[0m user_tensor \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mLongTensor([user_id] \u001B[38;5;241m*\u001B[39m \u001B[38;5;28mlen\u001B[39m(all_movie_ids))\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[0;32m---> 75\u001B[0m predictions \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43m{\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43muser\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43muser_tensor\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43munsqueeze\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmovie\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mall_movie_ids\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43munsqueeze\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m}\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     76\u001B[0m predictions \u001B[38;5;241m=\u001B[39m predictions\u001B[38;5;241m.\u001B[39msqueeze(\u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m     77\u001B[0m recommended_ids \u001B[38;5;241m=\u001B[39m predictions\u001B[38;5;241m.\u001B[39margsort(descending\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)[:suggestions_count]\n",
      "File \u001B[0;32m~/Source/edu/ai/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1734\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1735\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1736\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Source/edu/ai/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1742\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1743\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1744\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1745\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1746\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1747\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1749\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1750\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "Cell \u001B[0;32mIn[207], line 37\u001B[0m, in \u001B[0;36mDeepFM.forward\u001B[0;34m(self, batch)\u001B[0m\n\u001B[1;32m     34\u001B[0m user_emb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mflatten(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmovie_embeddings(batch[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmovie\u001B[39m\u001B[38;5;124m'\u001B[39m]))\n\u001B[1;32m     36\u001B[0m \u001B[38;5;66;03m# Compute mean of tag embeddings while ignoring padding (0)\u001B[39;00m\n\u001B[0;32m---> 37\u001B[0m tag_emb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtag_embeddings(\u001B[43mbatch\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mtags\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m)  \u001B[38;5;66;03m# Shape: [batch_size, max_tags_per_pair, tag_embedding_dim]\u001B[39;00m\n\u001B[1;32m     38\u001B[0m mask \u001B[38;5;241m=\u001B[39m (batch[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtags\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m0\u001B[39m)\u001B[38;5;241m.\u001B[39mfloat()\u001B[38;5;241m.\u001B[39munsqueeze(\u001B[38;5;241m2\u001B[39m)  \u001B[38;5;66;03m# Shape: [batch_size, max_tags_per_pair, 1]\u001B[39;00m\n\u001B[1;32m     39\u001B[0m tag_emb \u001B[38;5;241m=\u001B[39m (tag_emb \u001B[38;5;241m*\u001B[39m mask)\u001B[38;5;241m.\u001B[39msum(dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m) \u001B[38;5;241m/\u001B[39m mask\u001B[38;5;241m.\u001B[39msum(dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\u001B[38;5;241m.\u001B[39mclamp(\u001B[38;5;28mmin\u001B[39m\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)  \u001B[38;5;66;03m# Avoid division by 0\u001B[39;00m\n",
      "\u001B[0;31mKeyError\u001B[0m: 'tags'"
     ]
    }
   ],
   "execution_count": 208
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
