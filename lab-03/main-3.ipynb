{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Лаб-3. Рекомендательные системы"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T20:59:21.889060Z",
     "start_time": "2024-12-06T20:59:21.886074Z"
    }
   },
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "# Выбираем девайс\n",
    "USE_CUDA = False\n",
    "device = \"cuda\" if USE_CUDA and torch.cuda.is_available() else \"cpu\"\n",
    "print(f'Device: {device}')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n"
     ]
    }
   ],
   "execution_count": 229
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T20:59:21.947022Z",
     "start_time": "2024-12-06T20:59:21.912378Z"
    }
   },
   "source": [
    "OPTIMAL_TAGS_PER_PAIR_COUNT = 6\n",
    "# Для загрузки датасета напишем свою реализацию класса Dataset\n",
    "class MovielensDataset(Dataset):\n",
    "    r\"\"\"seed должен быть одинаковым для обучающей и тренировочной выборки\"\"\"\n",
    "    def __init__(self, source, train=True, seed=1, new_user_ratings=None, max_tags_per_pair=OPTIMAL_TAGS_PER_PAIR_COUNT):\n",
    "        self.max_tags_per_pair = max_tags_per_pair\n",
    "        ratings      = pd.read_csv(rf\"{source}/ratings.csv\")\n",
    "        self.movies  = pd.read_csv(rf\"{source}/movies.csv\")\n",
    "        self.tags = pd.read_csv(rf\"{source}/tags.csv\")\n",
    "        \n",
    "        # Преобразовываем Id фильмов в индексы в таблице movies\n",
    "        # x = self.movies.loc[:,['movieId']]\n",
    "        # x['movieId'], x.index = x.index, x['movieId'].values\n",
    "        # ratings['movieId'] = ratings['movieId'].map(x.to_dict()['movieId'])\n",
    "        \n",
    "        movie_id_map = pd.Series(self.movies.index, index=self.movies['movieId']).to_dict()\n",
    "        ratings['movieId'] = ratings['movieId'].map(movie_id_map)\n",
    "        \n",
    "        self.tag_id_map = {\n",
    "            tag: idx\n",
    "            for idx, tag in enumerate(self.tags['tag'].unique())\n",
    "        }\n",
    "        self.tags['movieId'] = self.tags['movieId'].map(movie_id_map)\n",
    "        self.tags['tagId'] = self.tags['tag'].map(self.tag_id_map)\n",
    "        print(self.tags)\n",
    "        \n",
    "        if new_user_ratings:\n",
    "            new_user_id = ratings['userId'].max() + 1\n",
    "            new_ratings = pd.DataFrame([\n",
    "                {\n",
    "                    'userId': new_user_id,\n",
    "                    'movieId': movie_idx,\n",
    "                    'rating': rating\n",
    "                } for movie_idx, rating in new_user_ratings\n",
    "            ])\n",
    "            ratings = pd.concat([ratings, new_ratings], ignore_index=True)\n",
    "\n",
    "        # делим датасет 80% на 20%\n",
    "        train_data = ratings.sample(frac=0.8, random_state=seed)\n",
    "        test_data  = ratings.drop(train_data.index)\n",
    "\n",
    "        self.ratings = train_data if train else test_data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ratings)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.ratings.iloc[idx]\n",
    "        user, movie = sample['userId'], sample['movieId']\n",
    "        tag_ids = self.tags[(self.tags['userId'] == user) & (self.tags['movieId'] == movie)]['tagId'].tolist()\n",
    "        \n",
    "        # pad/truncate tag_ids to fixed size\n",
    "        if len(tag_ids) < self.max_tags_per_pair:\n",
    "            tag_ids += [0] * (self.max_tags_per_pair - len(tag_ids))\n",
    "        else:\n",
    "            tag_ids = tag_ids[:self.max_tags_per_pair] \n",
    "        \n",
    "        return {\n",
    "            \"user\": torch.LongTensor([user]),\n",
    "            \"movie\": torch.LongTensor([movie]),\n",
    "            \"rating\": torch.FloatTensor([sample['rating']]),\n",
    "            \"tags\": torch.LongTensor(tag_ids)\n",
    "        }\n",
    "\n",
    "def generate_random_ratings(num_movies, num_ratings=20):\n",
    "    random_movies = random.sample(range(num_movies), num_ratings)\n",
    "    ratings = [(movie_idx, random.uniform(1, 5)) for movie_idx in random_movies]\n",
    "    return ratings\n",
    "\n",
    "def suggest_movies(model, user_id, movies_df, tags_tensor=None, suggestions_count=10):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        all_movie_ids = torch.arange(len(movies_df), dtype=torch.long).to(device)\n",
    "        user_tensor = torch.LongTensor([user_id] * len(all_movie_ids)).to(device)\n",
    "        \n",
    "        input_tags_tensor = torch.zeros(len(movies_df), OPTIMAL_TAGS_PER_PAIR_COUNT, dtype=torch.long) if tags_tensor is None else tags_tensor # lol\n",
    "        \n",
    "        predictions = model({\n",
    "            \"user\": user_tensor.unsqueeze(1),\n",
    "            \"movie\": all_movie_ids.unsqueeze(1),\n",
    "            \"tags\": input_tags_tensor.to(device),\n",
    "        })\n",
    "        predictions = predictions.squeeze(1)\n",
    "        recommended_ids = predictions.argsort(descending=True)[:suggestions_count]\n",
    "        return movies_df.iloc[recommended_ids.cpu().numpy()]"
   ],
   "outputs": [],
   "execution_count": 230
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T20:59:22.173992Z",
     "start_time": "2024-12-06T20:59:21.947934Z"
    }
   },
   "source": [
    "BATCH_SIZE = 200\n",
    "DATASET_SOURCE = r'./data'\n",
    "MOCK_RATINGS_COUNT = 20\n",
    "\n",
    "mock_ratings = generate_random_ratings(MOCK_RATINGS_COUNT)\n",
    "RATINGS = [\n",
    "    (111, 5.0), # 111,Taxi Driver (1976),Crime|Drama|Thriller\n",
    "    (55444, 4.5), # 55444,Control (2007),Drama\n",
    "    (88129, 5.0), # 88129,Drive (2011),Crime|Drama|Film-Noir|Thriller\n",
    "    (99114, 5.0), # 99114,Django Unchained (2012),Action|Drama|Western\n",
    "    (27156, 4.5), # 27156,\"Neon Genesis Evangelion: The End of Evangelion (Shin seiki Evangelion Gekijô-ban: Air/Magokoro wo, kimi ni) (1997)\",Action|Animation|Drama|Fantasy|Sci-Fi\n",
    "    (47423, 4.0), # 47423,Half Nelson (2006),Drama\n",
    "    (4306, 5.0), # 4306,Shrek (2001),Adventure|Animation|Children|Comedy|Fantasy|Romance\n",
    "    (8360, 5.0), # 8360,Shrek 2 (2004),Adventure|Animation|Children|Comedy|Musical|Romance\n",
    "    (53121, 5.0), # 53121,Shrek the Third (2007),Adventure|Animation|Children|Comedy|Fantasy\n",
    "    (541, 5.0), # 541,Blade Runner (1982),Action|Sci-Fi|Thriller\n",
    "    (122886,2.0), # 122886,Star Wars: Episode VII - The Force Awakens (2015),Action|Adventure|Fantasy|Sci-Fi|IMAX\n",
    "    (5444, 5.0), # 5444,Lilo & Stitch (2002),Adventure|Animation|Children|Sci-Fi\n",
    "    (171749, 4.0), # 171749,Death Note: Desu nôto (2006–2007),(no genres listed)\n",
    "    (47, 4.5), # 47,Seven (a.k.a. Se7en) (1995),Mystery|Thriller\n",
    "    (1201, 5.0), # 1201,\"Good, the Bad and the Ugly, The (Buono, il brutto, il cattivo, Il) (1966)\",Action|Adventure|Western\n",
    "    (2951, 5.0), # 2951,\"Fistful of Dollars, A (Per un pugno di dollari) (1964)\",Action|Western\n",
    "    (64614, 5.0), # 64614,Gran Torino (2008),Crime|Drama\n",
    "    (72737, 5.0), # 72737,\"Princess and the Frog, The (2009)\",Animation|Children|Fantasy|Musical|Romance\n",
    "    (101525, 3.5), # 101525,\"Place Beyond the Pines, The (2012)\",Crime|Drama\n",
    "    (31658, 5.0), # 31658,Howl's Moving Castle (Hauru no ugoku shiro) (2004),Adventure|Animation|Fantasy|Romance\n",
    "]\n",
    "\n",
    "movielens_train = MovielensDataset(DATASET_SOURCE, train=True, new_user_ratings=mock_ratings, max_tags_per_pair=OPTIMAL_TAGS_PER_PAIR_COUNT)\n",
    "movielens_test  = MovielensDataset(DATASET_SOURCE, train=False, max_tags_per_pair=OPTIMAL_TAGS_PER_PAIR_COUNT)\n",
    "\n",
    "train_loader = DataLoader(movielens_train, BATCH_SIZE, True)\n",
    "test_loader = DataLoader(movielens_test, BATCH_SIZE, True)\n",
    "\n",
    "for batch in train_loader:\n",
    "    for k, v in batch.items():\n",
    "        print(k, v.shape)\n",
    "    break"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      userId  movieId               tag   timestamp  tagId\n",
      "0          2     6801             funny  1445714994      0\n",
      "1          2     6801   Highly quotable  1445714996      1\n",
      "2          2     6801      will ferrell  1445714992      2\n",
      "3          2     7697      Boxing story  1445715207      3\n",
      "4          2     7697               MMA  1445715200      4\n",
      "...      ...      ...               ...         ...    ...\n",
      "3678     606     4925         for katie  1171234019   1584\n",
      "3679     606     5062           austere  1173392334   1585\n",
      "3680     610     2452            gun fu  1493843984   1586\n",
      "3681     610     2452  heroic bloodshed  1493843978   1587\n",
      "3682     610     9461  Heroic Bloodshed  1493844270   1588\n",
      "\n",
      "[3683 rows x 5 columns]\n",
      "      userId  movieId               tag   timestamp  tagId\n",
      "0          2     6801             funny  1445714994      0\n",
      "1          2     6801   Highly quotable  1445714996      1\n",
      "2          2     6801      will ferrell  1445714992      2\n",
      "3          2     7697      Boxing story  1445715207      3\n",
      "4          2     7697               MMA  1445715200      4\n",
      "...      ...      ...               ...         ...    ...\n",
      "3678     606     4925         for katie  1171234019   1584\n",
      "3679     606     5062           austere  1173392334   1585\n",
      "3680     610     2452            gun fu  1493843984   1586\n",
      "3681     610     2452  heroic bloodshed  1493843978   1587\n",
      "3682     610     9461  Heroic Bloodshed  1493844270   1588\n",
      "\n",
      "[3683 rows x 5 columns]\n",
      "user torch.Size([200, 1])\n",
      "movie torch.Size([200, 1])\n",
      "rating torch.Size([200, 1])\n",
      "tags torch.Size([200, 6])\n"
     ]
    }
   ],
   "execution_count": 231
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T20:59:22.178726Z",
     "start_time": "2024-12-06T20:59:22.174688Z"
    }
   },
   "source": [
    "# Функции для обучения из прошлой лабы, с учётом юзеров и айтемов\n",
    "\n",
    "def train_iteration(model, data_loader, loss_function, optimizer):\n",
    "    model.train()\n",
    "    train_size = len(data_loader.dataset)\n",
    "    for idx, batch in enumerate(data_loader):\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        pred = model(batch)\n",
    "        loss = loss_function(pred, batch['rating'])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        if idx % 100 == 0:\n",
    "            loss, current = loss.item(), (idx + 1) * BATCH_SIZE\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{train_size:>5d}]\")\n",
    "\n",
    "def test(model, data_loader, loss_function):\n",
    "    model.eval()\n",
    "    num_batches = len(data_loader)\n",
    "    loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader:\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            pred = model(batch)\n",
    "            loss += loss_function(pred, batch['rating']).item()\n",
    "\n",
    "    loss /= num_batches\n",
    "    print(f\"Avg loss: {loss:>8f} \\n\")\n",
    "\n",
    "\n",
    "def train(epochs, model, loss_function, optimizer):\n",
    "    for t in tqdm(range(epochs)):\n",
    "        print(f\"== Epoch {t + 1} ==\")\n",
    "        train_iteration(model, train_loader, loss_function, optimizer)\n",
    "        test(model, test_loader, loss_function)\n"
   ],
   "outputs": [],
   "execution_count": 232
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T20:59:22.253608Z",
     "start_time": "2024-12-06T20:59:22.179537Z"
    }
   },
   "cell_type": "code",
   "source": "sum([32,32])",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 233
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T21:04:50.362566Z",
     "start_time": "2024-12-06T20:59:22.254365Z"
    }
   },
   "source": [
    "class DeepFM(nn.Module):\n",
    "    def __init__(self, num_users=1000, num_movies=10000, num_tags=5000):\n",
    "        super().__init__()\n",
    "       \n",
    "        self.embeddings_dim = [32, 32, 16]\n",
    "        self.fm_dim = self.embeddings_dim[0]\n",
    "        \n",
    "        self.user_embeddings = nn.Embedding(num_users, self.embeddings_dim[0])\n",
    "        self.movie_embeddings = nn.Embedding(num_movies, self.embeddings_dim[1])\n",
    "        self.tag_embeddings = nn.Embedding(num_tags, self.embeddings_dim[2], padding_idx=0)\n",
    "\n",
    "        self.deep_input_dim = sum(self.embeddings_dim)\n",
    "        self.deep_linear_dim = 128\n",
    "        self.deep_output_dim = 128\n",
    "        \n",
    "        self.flatten = nn.Flatten()\n",
    "        self.deep_layers = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(self.deep_input_dim, self.deep_linear_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(self.deep_linear_dim, self.deep_linear_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.6),\n",
    "            nn.Linear(self.deep_linear_dim, self.deep_output_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.7),\n",
    "        )\n",
    "\n",
    "        self.final_layer = nn.Linear(self.deep_output_dim + self.fm_dim, 1)  # adjusted input size\n",
    "\n",
    "    def forward(self, batch):\n",
    "        movie_emb = self.flatten(self.user_embeddings(batch['user']))\n",
    "        user_emb = self.flatten(self.movie_embeddings(batch['movie']))\n",
    "\n",
    "        # Compute mean of tag embeddings while ignoring padding (0)\n",
    "        tag_emb = self.tag_embeddings(batch['tags'])  # Shape: [batch_size, max_tags_per_pair, tag_embedding_dim]\n",
    "        mask = (batch['tags'] != 0).float().unsqueeze(2)  # Shape: [batch_size, max_tags_per_pair, 1] (.unsqueeze(2) adds an extra dimension to make the mask compatible with tag_emb)\n",
    "        tag_emb = (tag_emb * mask).sum(dim=1) / mask.sum(dim=1).clamp(min=1)  # Avoid division by 0\n",
    "        \n",
    "        fm = movie_emb * user_emb\n",
    "\n",
    "        deep = torch.cat([movie_emb, user_emb, tag_emb], 1)\n",
    "        deep = self.deep_layers(deep)\n",
    "\n",
    "        v = torch.cat([fm, deep], 1)\n",
    "        v = self.final_layer(v)\n",
    "        # делаем сигмоиду на выходе и масштабируем к оценкам от 0 до 5\n",
    "        return torch.sigmoid(v) * 5\n",
    "\n",
    "EPOCHS_COUNT = 12\n",
    "LEARNING_RATE = 1e-3\n",
    "\n",
    "deep_mf_model = DeepFM(\n",
    "    num_users=movielens_train.ratings['userId'].max() + 1,\n",
    "    num_movies=len(movielens_train.movies),\n",
    "    num_tags=len(movielens_train.tag_id_map)\n",
    ").to(device)\n",
    "\n",
    "deep_mf_loss = nn.MSELoss()\n",
    "deep_mf_optimizer = torch.optim.Adam(deep_mf_model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "train(EPOCHS_COUNT, deep_mf_model, deep_mf_loss, deep_mf_optimizer)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/12 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Epoch 1 ==\n",
      "loss: 1.967423  [  200/80685]\n",
      "loss: 1.183876  [20200/80685]\n",
      "loss: 1.202168  [40200/80685]\n",
      "loss: 1.116380  [60200/80685]\n",
      "loss: 1.165775  [80200/80685]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 1/12 [00:27<05:05, 27.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg loss: 1.033046 \n",
      "\n",
      "== Epoch 2 ==\n",
      "loss: 1.015136  [  200/80685]\n",
      "loss: 1.028346  [20200/80685]\n",
      "loss: 0.901989  [40200/80685]\n",
      "loss: 1.098403  [60200/80685]\n",
      "loss: 0.822199  [80200/80685]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 2/12 [00:55<04:35, 27.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg loss: 0.944119 \n",
      "\n",
      "== Epoch 3 ==\n",
      "loss: 0.964525  [  200/80685]\n",
      "loss: 0.970662  [20200/80685]\n",
      "loss: 0.914172  [40200/80685]\n",
      "loss: 0.834400  [60200/80685]\n",
      "loss: 0.719647  [80200/80685]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 3/12 [01:22<04:08, 27.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg loss: 0.897558 \n",
      "\n",
      "== Epoch 4 ==\n",
      "loss: 0.961401  [  200/80685]\n",
      "loss: 0.946312  [20200/80685]\n",
      "loss: 0.899616  [40200/80685]\n",
      "loss: 0.877577  [60200/80685]\n",
      "loss: 1.022227  [80200/80685]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 4/12 [01:50<03:41, 27.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg loss: 0.881471 \n",
      "\n",
      "== Epoch 5 ==\n",
      "loss: 0.938379  [  200/80685]\n",
      "loss: 1.018596  [20200/80685]\n",
      "loss: 0.717430  [40200/80685]\n",
      "loss: 0.674308  [60200/80685]\n",
      "loss: 1.074329  [80200/80685]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 5/12 [02:18<03:13, 27.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg loss: 0.853121 \n",
      "\n",
      "== Epoch 6 ==\n",
      "loss: 0.767993  [  200/80685]\n",
      "loss: 0.639110  [20200/80685]\n",
      "loss: 1.084492  [40200/80685]\n",
      "loss: 0.702216  [60200/80685]\n",
      "loss: 0.680416  [80200/80685]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 6/12 [02:45<02:44, 27.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg loss: 0.831219 \n",
      "\n",
      "== Epoch 7 ==\n",
      "loss: 0.835399  [  200/80685]\n",
      "loss: 0.793097  [20200/80685]\n",
      "loss: 0.890510  [40200/80685]\n",
      "loss: 0.819290  [60200/80685]\n",
      "loss: 0.946277  [80200/80685]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 7/12 [03:13<02:17, 27.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg loss: 0.814371 \n",
      "\n",
      "== Epoch 8 ==\n",
      "loss: 0.667939  [  200/80685]\n",
      "loss: 0.726526  [20200/80685]\n",
      "loss: 0.818765  [40200/80685]\n",
      "loss: 0.657837  [60200/80685]\n",
      "loss: 0.737845  [80200/80685]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 8/12 [03:40<01:49, 27.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg loss: 0.805861 \n",
      "\n",
      "== Epoch 9 ==\n",
      "loss: 0.795882  [  200/80685]\n",
      "loss: 0.806924  [20200/80685]\n",
      "loss: 0.748494  [40200/80685]\n",
      "loss: 0.708619  [60200/80685]\n",
      "loss: 0.893086  [80200/80685]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 9/12 [04:06<01:21, 27.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg loss: 0.795254 \n",
      "\n",
      "== Epoch 10 ==\n",
      "loss: 0.734527  [  200/80685]\n",
      "loss: 0.860336  [20200/80685]\n",
      "loss: 0.703671  [40200/80685]\n",
      "loss: 0.720927  [60200/80685]\n",
      "loss: 0.751280  [80200/80685]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 10/12 [04:33<00:54, 27.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg loss: 0.793087 \n",
      "\n",
      "== Epoch 11 ==\n",
      "loss: 0.781425  [  200/80685]\n",
      "loss: 0.859548  [20200/80685]\n",
      "loss: 0.814076  [40200/80685]\n",
      "loss: 0.824850  [60200/80685]\n",
      "loss: 0.627271  [80200/80685]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 11/12 [05:00<00:26, 26.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg loss: 0.786756 \n",
      "\n",
      "== Epoch 12 ==\n",
      "loss: 0.753564  [  200/80685]\n",
      "loss: 0.846826  [20200/80685]\n",
      "loss: 0.607595  [40200/80685]\n",
      "loss: 0.795275  [60200/80685]\n",
      "loss: 0.705403  [80200/80685]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [05:28<00:00, 27.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg loss: 0.786445 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 234
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T21:04:50.377215Z",
     "start_time": "2024-12-06T21:04:50.363309Z"
    }
   },
   "cell_type": "code",
   "source": [
    "SUGGESTIONS_COUNT = 20\n",
    "\n",
    "print(\"Movie Recommendations for me:\")\n",
    "new_user_id = movielens_train.ratings['userId'].max()\n",
    "suggestions = suggest_movies(deep_mf_model, new_user_id, movielens_train.movies, suggestions_count=SUGGESTIONS_COUNT)\n",
    "suggestions"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movie Recommendations for me:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "      movieId                                              title  \\\n",
       "277       318                   Shawshank Redemption, The (1994)   \n",
       "6783    60333          Encounters at the End of the World (2008)   \n",
       "9027   140816                                   Tangerine (2015)   \n",
       "5733    30745        Gozu (Gokudô kyôfu dai-gekijô: Gozu) (2003)   \n",
       "2479     3302                            Beautiful People (1999)   \n",
       "8571   116817                                  Rudderless (2014)   \n",
       "348       391                               Jason's Lyric (1994)   \n",
       "8726   126921                     The Fox and the Hound 2 (2006)   \n",
       "863      1136             Monty Python and the Holy Grail (1975)   \n",
       "7180    72226                           Fantastic Mr. Fox (2009)   \n",
       "314       356                                Forrest Gump (1994)   \n",
       "2107     2801  Oscar and Lucinda (a.k.a. Oscar & Lucinda) (1997)   \n",
       "7239    73822                                    Meantime (1984)   \n",
       "7249    74226  Dream of Light (a.k.a. Quince Tree Sun, The) (...   \n",
       "899      1197                         Princess Bride, The (1987)   \n",
       "87         99               Heidi Fleiss: Hollywood Madam (1995)   \n",
       "9129   146662             Dragons: Gift of the Night Fury (2011)   \n",
       "841      1104                   Streetcar Named Desire, A (1951)   \n",
       "8185   103075                                  Purge, The (2013)   \n",
       "9551   173197                                  The Square (2017)   \n",
       "\n",
       "                                         genres  \n",
       "277                                 Crime|Drama  \n",
       "6783                                Documentary  \n",
       "9027                               Comedy|Drama  \n",
       "5733          Comedy|Crime|Drama|Horror|Mystery  \n",
       "2479                                     Comedy  \n",
       "8571                               Comedy|Drama  \n",
       "348                                 Crime|Drama  \n",
       "8726        Adventure|Animation|Children|Comedy  \n",
       "863                    Adventure|Comedy|Fantasy  \n",
       "7180  Adventure|Animation|Children|Comedy|Crime  \n",
       "314                    Comedy|Drama|Romance|War  \n",
       "2107                              Drama|Romance  \n",
       "7239                               Comedy|Drama  \n",
       "7249                          Documentary|Drama  \n",
       "899     Action|Adventure|Comedy|Fantasy|Romance  \n",
       "87                                  Documentary  \n",
       "9129                 Adventure|Animation|Comedy  \n",
       "841                                       Drama  \n",
       "8185                      Crime|Horror|Thriller  \n",
       "9551                                      Drama  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>318</td>\n",
       "      <td>Shawshank Redemption, The (1994)</td>\n",
       "      <td>Crime|Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6783</th>\n",
       "      <td>60333</td>\n",
       "      <td>Encounters at the End of the World (2008)</td>\n",
       "      <td>Documentary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9027</th>\n",
       "      <td>140816</td>\n",
       "      <td>Tangerine (2015)</td>\n",
       "      <td>Comedy|Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5733</th>\n",
       "      <td>30745</td>\n",
       "      <td>Gozu (Gokudô kyôfu dai-gekijô: Gozu) (2003)</td>\n",
       "      <td>Comedy|Crime|Drama|Horror|Mystery</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2479</th>\n",
       "      <td>3302</td>\n",
       "      <td>Beautiful People (1999)</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8571</th>\n",
       "      <td>116817</td>\n",
       "      <td>Rudderless (2014)</td>\n",
       "      <td>Comedy|Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>391</td>\n",
       "      <td>Jason's Lyric (1994)</td>\n",
       "      <td>Crime|Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8726</th>\n",
       "      <td>126921</td>\n",
       "      <td>The Fox and the Hound 2 (2006)</td>\n",
       "      <td>Adventure|Animation|Children|Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>863</th>\n",
       "      <td>1136</td>\n",
       "      <td>Monty Python and the Holy Grail (1975)</td>\n",
       "      <td>Adventure|Comedy|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7180</th>\n",
       "      <td>72226</td>\n",
       "      <td>Fantastic Mr. Fox (2009)</td>\n",
       "      <td>Adventure|Animation|Children|Comedy|Crime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>356</td>\n",
       "      <td>Forrest Gump (1994)</td>\n",
       "      <td>Comedy|Drama|Romance|War</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2107</th>\n",
       "      <td>2801</td>\n",
       "      <td>Oscar and Lucinda (a.k.a. Oscar &amp; Lucinda) (1997)</td>\n",
       "      <td>Drama|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7239</th>\n",
       "      <td>73822</td>\n",
       "      <td>Meantime (1984)</td>\n",
       "      <td>Comedy|Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7249</th>\n",
       "      <td>74226</td>\n",
       "      <td>Dream of Light (a.k.a. Quince Tree Sun, The) (...</td>\n",
       "      <td>Documentary|Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>899</th>\n",
       "      <td>1197</td>\n",
       "      <td>Princess Bride, The (1987)</td>\n",
       "      <td>Action|Adventure|Comedy|Fantasy|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>99</td>\n",
       "      <td>Heidi Fleiss: Hollywood Madam (1995)</td>\n",
       "      <td>Documentary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9129</th>\n",
       "      <td>146662</td>\n",
       "      <td>Dragons: Gift of the Night Fury (2011)</td>\n",
       "      <td>Adventure|Animation|Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>841</th>\n",
       "      <td>1104</td>\n",
       "      <td>Streetcar Named Desire, A (1951)</td>\n",
       "      <td>Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8185</th>\n",
       "      <td>103075</td>\n",
       "      <td>Purge, The (2013)</td>\n",
       "      <td>Crime|Horror|Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9551</th>\n",
       "      <td>173197</td>\n",
       "      <td>The Square (2017)</td>\n",
       "      <td>Drama</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 235
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
