{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Лаб-3. Рекомендательные системы"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T23:20:31.293902Z",
     "start_time": "2024-12-06T23:20:31.291258Z"
    }
   },
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "# Выбираем девайс\n",
    "USE_CUDA = False\n",
    "device = \"cuda\" if USE_CUDA and torch.cuda.is_available() else \"cpu\"\n",
    "print(f'Device: {device}')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T23:20:31.427524Z",
     "start_time": "2024-12-06T23:20:31.295227Z"
    }
   },
   "source": [
    "OPTIMAL_TAGS_PER_PAIR_COUNT = 6\n",
    "# Для загрузки датасета напишем свою реализацию класса Dataset\n",
    "class MovielensDataset(Dataset):\n",
    "    r\"\"\"seed должен быть одинаковым для обучающей и тренировочной выборки\"\"\"\n",
    "    def __init__(self, source, train=True, seed=1, new_user_ratings=None, max_tags_per_pair=OPTIMAL_TAGS_PER_PAIR_COUNT):\n",
    "        self.max_tags_per_pair = max_tags_per_pair\n",
    "        ratings      = pd.read_csv(rf\"{source}/ratings.csv\")\n",
    "        self.movies  = pd.read_csv(rf\"{source}/movies.csv\")\n",
    "        self.tags = pd.read_csv(rf\"{source}/tags.csv\")\n",
    "        \n",
    "        title_basics = pd.read_csv(f\"{source}/title.basics.filtered.csv\", dtype={\n",
    "            'imdbId': str,  # make sure imdbId is treated as a string\n",
    "            'isAdult': 'int8',  # isAdult should be a binary column (0 or 1)\n",
    "            'primaryTitle': str,\n",
    "            'originalTitle': str,\n",
    "            'startYear': str,\n",
    "            'endYear': str,\n",
    "            'runtimeMinutes': str,\n",
    "            'genres': str\n",
    "        })\n",
    "        # Step 2: Parse links.csv to link movieId and imdbId\n",
    "        links = pd.read_csv(f\"{source}/links.csv\", dtype={'movieId': 'int32', 'imdbId': str, 'tmdbId': str})\n",
    "        \n",
    "        # Merge links df with title_basics df on imdbId. This allows us to map movieId to the corresponding title_basics data\n",
    "        movie_details = pd.merge(links, title_basics[['imdbId', 'isAdult']], on='imdbId', how='left')\n",
    "        # merge isAdult column into self.movies    \n",
    "        self.movies = pd.merge(self.movies, movie_details[['movieId', 'isAdult']], on='movieId', how='left')\n",
    "\n",
    "    \n",
    "        # Преобразовываем Id фильмов в индексы в таблице movies\n",
    "        # x = self.movies.loc[:,['movieId']]\n",
    "        # x['movieId'], x.index = x.index, x['movieId'].values\n",
    "        # ratings['movieId'] = ratings['movieId'].map(x.to_dict()['movieId'])\n",
    "        \n",
    "        movie_id_map = pd.Series(self.movies.index, index=self.movies['movieId']).to_dict()\n",
    "        ratings['movieId'] = ratings['movieId'].map(movie_id_map)\n",
    "        \n",
    "        self.tag_id_map = {\n",
    "            tag: idx\n",
    "            for idx, tag in enumerate(self.tags['tag'].unique())\n",
    "        }\n",
    "        self.tags['movieId'] = self.tags['movieId'].map(movie_id_map)\n",
    "        self.tags['tagId'] = self.tags['tag'].map(self.tag_id_map)\n",
    "        print(self.tags)\n",
    "        \n",
    "        if new_user_ratings:\n",
    "            new_user_id = ratings['userId'].max() + 1\n",
    "            new_ratings = pd.DataFrame([\n",
    "                {\n",
    "                    'userId': new_user_id,\n",
    "                    'movieId': movie_idx,\n",
    "                    'rating': rating\n",
    "                } for movie_idx, rating in new_user_ratings\n",
    "            ])\n",
    "            ratings = pd.concat([ratings, new_ratings], ignore_index=True)\n",
    "\n",
    "        # делим датасет 80% на 20%\n",
    "        train_data = ratings.sample(frac=0.8, random_state=seed)\n",
    "        test_data  = ratings.drop(train_data.index)\n",
    "\n",
    "        self.ratings = train_data if train else test_data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ratings)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.ratings.iloc[idx]\n",
    "        user, movie = sample['userId'], sample['movieId']\n",
    "        tag_ids = self.tags[(self.tags['userId'] == user) & (self.tags['movieId'] == movie)]['tagId'].tolist()\n",
    "        \n",
    "        # pad/truncate tag_ids to fixed size\n",
    "        if len(tag_ids) < self.max_tags_per_pair:\n",
    "            tag_ids += [0] * (self.max_tags_per_pair - len(tag_ids))\n",
    "        else:\n",
    "            tag_ids = tag_ids[:self.max_tags_per_pair] \n",
    "        \n",
    "        return {\n",
    "            \"user\": torch.LongTensor([user]),\n",
    "            \"movie\": torch.LongTensor([movie]),\n",
    "            \"rating\": torch.FloatTensor([sample['rating']]),\n",
    "            \"tags\": torch.LongTensor(tag_ids)\n",
    "        }\n",
    "\n",
    "def generate_random_ratings(num_movies, num_ratings=20):\n",
    "    random_movies = random.sample(range(num_movies), num_ratings)\n",
    "    ratings = [(movie_idx, random.uniform(1, 5)) for movie_idx in random_movies]\n",
    "    return ratings\n",
    "\n",
    "def suggest_movies(model, user_id, movies_df, tags_tensor=None, suggestions_count=10):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        all_movie_ids = torch.arange(len(movies_df), dtype=torch.long).to(device)\n",
    "        user_tensor = torch.LongTensor([user_id] * len(all_movie_ids)).to(device)\n",
    "        \n",
    "        input_tags_tensor = torch.zeros(len(movies_df), OPTIMAL_TAGS_PER_PAIR_COUNT, dtype=torch.long) if tags_tensor is None else tags_tensor # lol\n",
    "        \n",
    "        predictions = model({\n",
    "            \"user\": user_tensor.unsqueeze(1),\n",
    "            \"movie\": all_movie_ids.unsqueeze(1),\n",
    "            \"tags\": input_tags_tensor.to(device),\n",
    "        })\n",
    "        predictions = predictions.squeeze(1)\n",
    "        recommended_ids = predictions.argsort(descending=True)[:suggestions_count]\n",
    "        return movies_df.iloc[recommended_ids.cpu().numpy()]"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T23:20:33.899230Z",
     "start_time": "2024-12-06T23:20:31.428150Z"
    }
   },
   "source": [
    "BATCH_SIZE = 200\n",
    "DATASET_SOURCE = r'./data'\n",
    "MOCK_RATINGS_COUNT = 20\n",
    "\n",
    "mock_ratings = generate_random_ratings(MOCK_RATINGS_COUNT)\n",
    "RATINGS = [\n",
    "    (111, 5.0), # 111,Taxi Driver (1976),Crime|Drama|Thriller\n",
    "    (55444, 4.5), # 55444,Control (2007),Drama\n",
    "    (88129, 5.0), # 88129,Drive (2011),Crime|Drama|Film-Noir|Thriller\n",
    "    (99114, 5.0), # 99114,Django Unchained (2012),Action|Drama|Western\n",
    "    (27156, 4.5), # 27156,\"Neon Genesis Evangelion: The End of Evangelion (Shin seiki Evangelion Gekijô-ban: Air/Magokoro wo, kimi ni) (1997)\",Action|Animation|Drama|Fantasy|Sci-Fi\n",
    "    (47423, 4.0), # 47423,Half Nelson (2006),Drama\n",
    "    (4306, 5.0), # 4306,Shrek (2001),Adventure|Animation|Children|Comedy|Fantasy|Romance\n",
    "    (8360, 5.0), # 8360,Shrek 2 (2004),Adventure|Animation|Children|Comedy|Musical|Romance\n",
    "    (53121, 5.0), # 53121,Shrek the Third (2007),Adventure|Animation|Children|Comedy|Fantasy\n",
    "    (541, 5.0), # 541,Blade Runner (1982),Action|Sci-Fi|Thriller\n",
    "    (122886,2.0), # 122886,Star Wars: Episode VII - The Force Awakens (2015),Action|Adventure|Fantasy|Sci-Fi|IMAX\n",
    "    (5444, 5.0), # 5444,Lilo & Stitch (2002),Adventure|Animation|Children|Sci-Fi\n",
    "    (171749, 4.0), # 171749,Death Note: Desu nôto (2006–2007),(no genres listed)\n",
    "    (47, 4.5), # 47,Seven (a.k.a. Se7en) (1995),Mystery|Thriller\n",
    "    (1201, 5.0), # 1201,\"Good, the Bad and the Ugly, The (Buono, il brutto, il cattivo, Il) (1966)\",Action|Adventure|Western\n",
    "    (2951, 5.0), # 2951,\"Fistful of Dollars, A (Per un pugno di dollari) (1964)\",Action|Western\n",
    "    (64614, 5.0), # 64614,Gran Torino (2008),Crime|Drama\n",
    "    (72737, 5.0), # 72737,\"Princess and the Frog, The (2009)\",Animation|Children|Fantasy|Musical|Romance\n",
    "    (101525, 3.5), # 101525,\"Place Beyond the Pines, The (2012)\",Crime|Drama\n",
    "    (31658, 5.0), # 31658,Howl's Moving Castle (Hauru no ugoku shiro) (2004),Adventure|Animation|Fantasy|Romance\n",
    "]\n",
    "\n",
    "movielens_train = MovielensDataset(DATASET_SOURCE, train=True, new_user_ratings=mock_ratings, max_tags_per_pair=OPTIMAL_TAGS_PER_PAIR_COUNT)\n",
    "movielens_test  = MovielensDataset(DATASET_SOURCE, train=False, max_tags_per_pair=OPTIMAL_TAGS_PER_PAIR_COUNT)\n",
    "\n",
    "train_loader = DataLoader(movielens_train, BATCH_SIZE, True)\n",
    "test_loader = DataLoader(movielens_test, BATCH_SIZE, True)\n",
    "\n",
    "for batch in train_loader:\n",
    "    for k, v in batch.items():\n",
    "        print(k, v.shape)\n",
    "    break"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      userId  movieId               tag   timestamp  tagId\n",
      "0          2     6801             funny  1445714994      0\n",
      "1          2     6801   Highly quotable  1445714996      1\n",
      "2          2     6801      will ferrell  1445714992      2\n",
      "3          2     7697      Boxing story  1445715207      3\n",
      "4          2     7697               MMA  1445715200      4\n",
      "...      ...      ...               ...         ...    ...\n",
      "3678     606     4925         for katie  1171234019   1584\n",
      "3679     606     5062           austere  1173392334   1585\n",
      "3680     610     2452            gun fu  1493843984   1586\n",
      "3681     610     2452  heroic bloodshed  1493843978   1587\n",
      "3682     610     9461  Heroic Bloodshed  1493844270   1588\n",
      "\n",
      "[3683 rows x 5 columns]\n",
      "      userId  movieId               tag   timestamp  tagId\n",
      "0          2     6801             funny  1445714994      0\n",
      "1          2     6801   Highly quotable  1445714996      1\n",
      "2          2     6801      will ferrell  1445714992      2\n",
      "3          2     7697      Boxing story  1445715207      3\n",
      "4          2     7697               MMA  1445715200      4\n",
      "...      ...      ...               ...         ...    ...\n",
      "3678     606     4925         for katie  1171234019   1584\n",
      "3679     606     5062           austere  1173392334   1585\n",
      "3680     610     2452            gun fu  1493843984   1586\n",
      "3681     610     2452  heroic bloodshed  1493843978   1587\n",
      "3682     610     9461  Heroic Bloodshed  1493844270   1588\n",
      "\n",
      "[3683 rows x 5 columns]\n",
      "user torch.Size([200, 1])\n",
      "movie torch.Size([200, 1])\n",
      "rating torch.Size([200, 1])\n",
      "tags torch.Size([200, 6])\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T23:20:33.904477Z",
     "start_time": "2024-12-06T23:20:33.900181Z"
    }
   },
   "source": [
    "# Функции для обучения из прошлой лабы, с учётом юзеров и айтемов\n",
    "\n",
    "def train_iteration(model, data_loader, loss_function, optimizer):\n",
    "    model.train()\n",
    "    train_size = len(data_loader.dataset)\n",
    "    for idx, batch in enumerate(data_loader):\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        pred = model(batch)\n",
    "        loss = loss_function(pred, batch['rating'])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        if idx % 100 == 0:\n",
    "            loss, current = loss.item(), (idx + 1) * BATCH_SIZE\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{train_size:>5d}]\")\n",
    "\n",
    "def test(model, data_loader, loss_function):\n",
    "    model.eval()\n",
    "    num_batches = len(data_loader)\n",
    "    loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader:\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            pred = model(batch)\n",
    "            loss += loss_function(pred, batch['rating']).item()\n",
    "\n",
    "    loss /= num_batches\n",
    "    print(f\"Avg loss: {loss:>8f} \\n\")\n",
    "\n",
    "\n",
    "def train(epochs, model, loss_function, optimizer):\n",
    "    for t in tqdm(range(epochs)):\n",
    "        print(f\"== Epoch {t + 1} ==\")\n",
    "        train_iteration(model, train_loader, loss_function, optimizer)\n",
    "        test(model, test_loader, loss_function)\n"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T23:20:33.999278Z",
     "start_time": "2024-12-06T23:20:33.905135Z"
    }
   },
   "cell_type": "code",
   "source": "sum([32,32])",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T23:20:50.238905Z",
     "start_time": "2024-12-06T23:20:33.999935Z"
    }
   },
   "source": [
    "class DeepFM(nn.Module):\n",
    "    def __init__(self, num_users=1000, num_movies=10000, num_tags=5000):\n",
    "        super().__init__()\n",
    "       \n",
    "        self.embeddings_dim = [32, 32, 16]\n",
    "        self.fm_dim = self.embeddings_dim[0]\n",
    "        \n",
    "        self.user_embeddings = nn.Embedding(num_users, self.embeddings_dim[0])\n",
    "        self.movie_embeddings = nn.Embedding(num_movies, self.embeddings_dim[1])\n",
    "        self.tag_embeddings = nn.Embedding(num_tags, self.embeddings_dim[2], padding_idx=0)\n",
    "\n",
    "        self.deep_input_dim = sum(self.embeddings_dim)\n",
    "        self.deep_linear_dim = 128\n",
    "        self.deep_output_dim = 128\n",
    "        \n",
    "        self.flatten = nn.Flatten()\n",
    "        self.deep_layers = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(self.deep_input_dim, self.deep_linear_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(self.deep_linear_dim, self.deep_linear_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.6),\n",
    "            nn.Linear(self.deep_linear_dim, self.deep_output_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.7),\n",
    "        )\n",
    "\n",
    "        self.final_layer = nn.Linear(self.deep_output_dim + self.fm_dim, 1)  # adjusted input size\n",
    "\n",
    "    def forward(self, batch):\n",
    "        movie_emb = self.flatten(self.user_embeddings(batch['user']))\n",
    "        user_emb = self.flatten(self.movie_embeddings(batch['movie']))\n",
    "\n",
    "        # Compute mean of tag embeddings while ignoring padding (0)\n",
    "        tag_emb = self.tag_embeddings(batch['tags'])  # Shape: [batch_size, max_tags_per_pair, tag_embedding_dim]\n",
    "        mask = (batch['tags'] != 0).float().unsqueeze(2)  # Shape: [batch_size, max_tags_per_pair, 1] (.unsqueeze(2) adds an extra dimension to make the mask compatible with tag_emb)\n",
    "        tag_emb = (tag_emb * mask).sum(dim=1) / mask.sum(dim=1).clamp(min=1)  # Avoid division by 0\n",
    "        \n",
    "        fm = movie_emb * user_emb\n",
    "\n",
    "        deep = torch.cat([movie_emb, user_emb, tag_emb], 1)\n",
    "        deep = self.deep_layers(deep)\n",
    "\n",
    "        v = torch.cat([fm, deep], 1)\n",
    "        v = self.final_layer(v)\n",
    "        # делаем сигмоиду на выходе и масштабируем к оценкам от 0 до 5\n",
    "        return torch.sigmoid(v) * 5\n",
    "\n",
    "EPOCHS_COUNT = 1\n",
    "LEARNING_RATE = 1e-3\n",
    "\n",
    "deep_mf_model = DeepFM(\n",
    "    num_users=movielens_train.ratings['userId'].max() + 1,\n",
    "    num_movies=len(movielens_train.movies),\n",
    "    num_tags=len(movielens_train.tag_id_map)\n",
    ").to(device)\n",
    "\n",
    "deep_mf_loss = nn.MSELoss()\n",
    "deep_mf_optimizer = torch.optim.Adam(deep_mf_model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "train(EPOCHS_COUNT, deep_mf_model, deep_mf_loss, deep_mf_optimizer)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Epoch 1 ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/heyra/Source/edu/ai/venv/lib/python3.12/site-packages/torch/autograd/graph.py:825: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 2.412887  [  200/80685]\n",
      "loss: 1.277790  [20200/80685]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:12<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[12], line 63\u001B[0m\n\u001B[1;32m     60\u001B[0m deep_mf_loss \u001B[38;5;241m=\u001B[39m nn\u001B[38;5;241m.\u001B[39mMSELoss()\n\u001B[1;32m     61\u001B[0m deep_mf_optimizer \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39moptim\u001B[38;5;241m.\u001B[39mAdam(deep_mf_model\u001B[38;5;241m.\u001B[39mparameters(), lr\u001B[38;5;241m=\u001B[39mLEARNING_RATE)\n\u001B[0;32m---> 63\u001B[0m \u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mEPOCHS_COUNT\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdeep_mf_model\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdeep_mf_loss\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdeep_mf_optimizer\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[10], line 34\u001B[0m, in \u001B[0;36mtrain\u001B[0;34m(epochs, model, loss_function, optimizer)\u001B[0m\n\u001B[1;32m     32\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m t \u001B[38;5;129;01min\u001B[39;00m tqdm(\u001B[38;5;28mrange\u001B[39m(epochs)):\n\u001B[1;32m     33\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m== Epoch \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mt\u001B[38;5;250m \u001B[39m\u001B[38;5;241m+\u001B[39m\u001B[38;5;250m \u001B[39m\u001B[38;5;241m1\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m ==\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m---> 34\u001B[0m     \u001B[43mtrain_iteration\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mloss_function\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     35\u001B[0m     test(model, test_loader, loss_function)\n",
      "Cell \u001B[0;32mIn[10], line 6\u001B[0m, in \u001B[0;36mtrain_iteration\u001B[0;34m(model, data_loader, loss_function, optimizer)\u001B[0m\n\u001B[1;32m      4\u001B[0m model\u001B[38;5;241m.\u001B[39mtrain()\n\u001B[1;32m      5\u001B[0m train_size \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(data_loader\u001B[38;5;241m.\u001B[39mdataset)\n\u001B[0;32m----> 6\u001B[0m \u001B[43m\u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43midx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43menumerate\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mdata_loader\u001B[49m\u001B[43m)\u001B[49m\u001B[43m:\u001B[49m\n\u001B[1;32m      7\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43m{\u001B[49m\u001B[43mk\u001B[49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mv\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mk\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mv\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mbatch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mitems\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m}\u001B[49m\n\u001B[1;32m      8\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpred\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Source/edu/ai/venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:701\u001B[0m, in \u001B[0;36m_BaseDataLoaderIter.__next__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    698\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    699\u001B[0m     \u001B[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001B[39;00m\n\u001B[1;32m    700\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reset()  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n\u001B[0;32m--> 701\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_next_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    702\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m    703\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[1;32m    704\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable\n\u001B[1;32m    705\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    706\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called\n\u001B[1;32m    707\u001B[0m ):\n",
      "File \u001B[0;32m~/Source/edu/ai/venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:757\u001B[0m, in \u001B[0;36m_SingleProcessDataLoaderIter._next_data\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    755\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_next_data\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    756\u001B[0m     index \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_next_index()  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[0;32m--> 757\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_dataset_fetcher\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfetch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mindex\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[1;32m    758\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory:\n\u001B[1;32m    759\u001B[0m         data \u001B[38;5;241m=\u001B[39m _utils\u001B[38;5;241m.\u001B[39mpin_memory\u001B[38;5;241m.\u001B[39mpin_memory(data, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory_device)\n",
      "File \u001B[0;32m~/Source/edu/ai/venv/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py:52\u001B[0m, in \u001B[0;36m_MapDatasetFetcher.fetch\u001B[0;34m(self, possibly_batched_index)\u001B[0m\n\u001B[1;32m     50\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset\u001B[38;5;241m.\u001B[39m__getitems__(possibly_batched_index)\n\u001B[1;32m     51\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m---> 52\u001B[0m         data \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdataset\u001B[49m\u001B[43m[\u001B[49m\u001B[43midx\u001B[49m\u001B[43m]\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m possibly_batched_index]\n\u001B[1;32m     53\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m     54\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[possibly_batched_index]\n",
      "Cell \u001B[0;32mIn[8], line 69\u001B[0m, in \u001B[0;36mMovielensDataset.__getitem__\u001B[0;34m(self, idx)\u001B[0m\n\u001B[1;32m     67\u001B[0m sample \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mratings\u001B[38;5;241m.\u001B[39miloc[idx]\n\u001B[1;32m     68\u001B[0m user, movie \u001B[38;5;241m=\u001B[39m sample[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124muserId\u001B[39m\u001B[38;5;124m'\u001B[39m], sample[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmovieId\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[0;32m---> 69\u001B[0m tag_ids \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtags[(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtags[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124muserId\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m==\u001B[39m user) \u001B[38;5;241m&\u001B[39m (\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtags\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mmovieId\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m==\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mmovie\u001B[49m)][\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtagId\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mtolist()\n\u001B[1;32m     71\u001B[0m \u001B[38;5;66;03m# pad/truncate tag_ids to fixed size\u001B[39;00m\n\u001B[1;32m     72\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(tag_ids) \u001B[38;5;241m<\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmax_tags_per_pair:\n",
      "File \u001B[0;32m~/Source/edu/ai/venv/lib/python3.12/site-packages/pandas/core/ops/common.py:76\u001B[0m, in \u001B[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001B[0;34m(self, other)\u001B[0m\n\u001B[1;32m     72\u001B[0m             \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mNotImplemented\u001B[39m\n\u001B[1;32m     74\u001B[0m other \u001B[38;5;241m=\u001B[39m item_from_zerodim(other)\n\u001B[0;32m---> 76\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mmethod\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mother\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Source/edu/ai/venv/lib/python3.12/site-packages/pandas/core/arraylike.py:40\u001B[0m, in \u001B[0;36mOpsMixin.__eq__\u001B[0;34m(self, other)\u001B[0m\n\u001B[1;32m     38\u001B[0m \u001B[38;5;129m@unpack_zerodim_and_defer\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m__eq__\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     39\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__eq__\u001B[39m(\u001B[38;5;28mself\u001B[39m, other):\n\u001B[0;32m---> 40\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_cmp_method\u001B[49m\u001B[43m(\u001B[49m\u001B[43mother\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moperator\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43meq\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Source/edu/ai/venv/lib/python3.12/site-packages/pandas/core/series.py:6121\u001B[0m, in \u001B[0;36mSeries._cmp_method\u001B[0;34m(self, other, op)\u001B[0m\n\u001B[1;32m   6117\u001B[0m rvalues \u001B[38;5;241m=\u001B[39m extract_array(other, extract_numpy\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, extract_range\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m   6119\u001B[0m res_values \u001B[38;5;241m=\u001B[39m ops\u001B[38;5;241m.\u001B[39mcomparison_op(lvalues, rvalues, op)\n\u001B[0;32m-> 6121\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_construct_result\u001B[49m\u001B[43m(\u001B[49m\u001B[43mres_values\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mres_name\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Source/edu/ai/venv/lib/python3.12/site-packages/pandas/core/series.py:6231\u001B[0m, in \u001B[0;36mSeries._construct_result\u001B[0;34m(self, result, name)\u001B[0m\n\u001B[1;32m   6228\u001B[0m \u001B[38;5;66;03m# TODO: result should always be ArrayLike, but this fails for some\u001B[39;00m\n\u001B[1;32m   6229\u001B[0m \u001B[38;5;66;03m#  JSONArray tests\u001B[39;00m\n\u001B[1;32m   6230\u001B[0m dtype \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mgetattr\u001B[39m(result, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdtype\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[0;32m-> 6231\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_constructor\u001B[49m\u001B[43m(\u001B[49m\u001B[43mresult\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mindex\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mindex\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcopy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[1;32m   6232\u001B[0m out \u001B[38;5;241m=\u001B[39m out\u001B[38;5;241m.\u001B[39m__finalize__(\u001B[38;5;28mself\u001B[39m)\n\u001B[1;32m   6234\u001B[0m \u001B[38;5;66;03m# Set the result's name after __finalize__ is called because __finalize__\u001B[39;00m\n\u001B[1;32m   6235\u001B[0m \u001B[38;5;66;03m#  would set it back to self.name\u001B[39;00m\n",
      "File \u001B[0;32m~/Source/edu/ai/venv/lib/python3.12/site-packages/pandas/core/series.py:493\u001B[0m, in \u001B[0;36mSeries.__init__\u001B[0;34m(self, data, index, dtype, name, copy, fastpath)\u001B[0m\n\u001B[1;32m    490\u001B[0m     index \u001B[38;5;241m=\u001B[39m ensure_index(index)\n\u001B[1;32m    492\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m dtype \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 493\u001B[0m     dtype \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_validate_dtype\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    495\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m data \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    496\u001B[0m     index \u001B[38;5;241m=\u001B[39m index \u001B[38;5;28;01mif\u001B[39;00m index \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m default_index(\u001B[38;5;241m0\u001B[39m)\n",
      "File \u001B[0;32m~/Source/edu/ai/venv/lib/python3.12/site-packages/pandas/core/generic.py:516\u001B[0m, in \u001B[0;36mNDFrame._validate_dtype\u001B[0;34m(cls, dtype)\u001B[0m\n\u001B[1;32m    514\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"validate the passed dtype\"\"\"\u001B[39;00m\n\u001B[1;32m    515\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m dtype \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 516\u001B[0m     dtype \u001B[38;5;241m=\u001B[39m \u001B[43mpandas_dtype\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    518\u001B[0m     \u001B[38;5;66;03m# a compound dtype\u001B[39;00m\n\u001B[1;32m    519\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m dtype\u001B[38;5;241m.\u001B[39mkind \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mV\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n",
      "File \u001B[0;32m~/Source/edu/ai/venv/lib/python3.12/site-packages/pandas/core/dtypes/common.py:1596\u001B[0m, in \u001B[0;36mpandas_dtype\u001B[0;34m(dtype)\u001B[0m\n\u001B[1;32m   1592\u001B[0m             \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00merror_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m must be a hashable type\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m   1593\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAll elements must be hashable\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m-> 1596\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mpandas_dtype\u001B[39m(dtype) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m DtypeObj:\n\u001B[1;32m   1597\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   1598\u001B[0m \u001B[38;5;124;03m    Convert input into a pandas only dtype object or a numpy dtype object.\u001B[39;00m\n\u001B[1;32m   1599\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1615\u001B[0m \u001B[38;5;124;03m    dtype('int64')\u001B[39;00m\n\u001B[1;32m   1616\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m   1617\u001B[0m     \u001B[38;5;66;03m# short-circuit\u001B[39;00m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "SUGGESTIONS_COUNT = 20\n",
    "\n",
    "print(\"Movie Recommendations for me:\")\n",
    "new_user_id = movielens_train.ratings['userId'].max()\n",
    "suggestions = suggest_movies(deep_mf_model, new_user_id, movielens_train.movies, suggestions_count=SUGGESTIONS_COUNT)\n",
    "suggestions"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
