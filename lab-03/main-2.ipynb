{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Лаб-3. Рекомендательные системы"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T00:31:30.175382Z",
     "start_time": "2024-12-06T00:31:30.172988Z"
    }
   },
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "# Выбираем девайс\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f'Device: {device}')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T00:31:30.247547Z",
     "start_time": "2024-12-06T00:31:30.180582Z"
    }
   },
   "source": [
    "# Для загрузки датасета напишем свою реализацию класса Dataset\n",
    "class MovielensDataset(Dataset):\n",
    "    r\"\"\"seed должен быть одинаковым для обучающей и тренировочной выборки\"\"\"\n",
    "    def __init__(self, source, train=True, seed=1, new_user_ratings=None):\n",
    "        ratings      = pd.read_csv(rf\"{source}/ratings.csv\")\n",
    "        self.movies  = pd.read_csv(rf\"{source}/movies.csv\")\n",
    "\n",
    "        # Преобразовываем Id фильмов в индексы в таблице movies\n",
    "        x = self.movies.loc[:,['movieId']]\n",
    "        x['movieId'], x.index = x.index, x['movieId'].values\n",
    "        ratings['movieId'] = ratings['movieId'].map(x.to_dict()['movieId'])\n",
    "\n",
    "        if new_user_ratings:\n",
    "            new_user_id = ratings['userId'].max() + 1\n",
    "            new_ratings = pd.DataFrame([\n",
    "                {\n",
    "                    'userId': new_user_id,\n",
    "                    'movieId': movie_idx,\n",
    "                    'rating': rating\n",
    "                } for movie_idx, rating in new_user_ratings\n",
    "            ])\n",
    "            ratings = pd.concat([ratings, new_ratings], ignore_index=True)\n",
    "\n",
    "        # делим датасет 80% на 20%\n",
    "        train_data = ratings.sample(frac=0.8, random_state=seed)\n",
    "        test_data  = ratings.drop(train_data.index)\n",
    "\n",
    "        self.ratings = train_data if train else test_data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ratings)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.ratings.iloc[idx]\n",
    "        return {\n",
    "            \"user\": torch.LongTensor([sample['userId']]),\n",
    "            \"movie\": torch.LongTensor([sample['movieId']]),\n",
    "            \"rating\": torch.FloatTensor([sample['rating']])\n",
    "        }\n",
    "\n",
    "def generate_random_ratings(num_movies, num_ratings=20):\n",
    "    random_movies = random.sample(range(num_movies), num_ratings)\n",
    "    ratings = [(movie_idx, random.uniform(1, 5)) for movie_idx in random_movies]\n",
    "    return ratings\n",
    "\n",
    "def suggest_movies(model, user_id, movies_df, suggestions_count=10):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        all_movie_ids = torch.arange(len(movies_df), dtype=torch.long).to(device)\n",
    "        user_tensor = torch.LongTensor([user_id] * len(all_movie_ids)).to(device)\n",
    "        predictions = model({\"user\": user_tensor.unsqueeze(1), \"movie\": all_movie_ids.unsqueeze(1)})\n",
    "        predictions = predictions.squeeze(1)\n",
    "        recommended_ids = predictions.argsort(descending=True)[:suggestions_count]\n",
    "        return movies_df.iloc[recommended_ids.cpu().numpy()]"
   ],
   "outputs": [],
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T00:31:30.419453Z",
     "start_time": "2024-12-06T00:31:30.248378Z"
    }
   },
   "source": [
    "BATCH_SIZE = 200\n",
    "DATASET_SOURCE = r'./data'\n",
    "MOCK_RATINGS_COUNT = 20\n",
    "\n",
    "# mock_ratings = generate_random_ratings(MOCK_RATINGS_COUNT)\n",
    "RATINGS = [\n",
    "    (111, 5.0), # 111,Taxi Driver (1976),Crime|Drama|Thriller\n",
    "    (55444, 4.5), # 55444,Control (2007),Drama\n",
    "    (88129, 5.0), # 88129,Drive (2011),Crime|Drama|Film-Noir|Thriller\n",
    "    (99114, 5.0), # 99114,Django Unchained (2012),Action|Drama|Western\n",
    "    (27156, 4.5), # 27156,\"Neon Genesis Evangelion: The End of Evangelion (Shin seiki Evangelion Gekijô-ban: Air/Magokoro wo, kimi ni) (1997)\",Action|Animation|Drama|Fantasy|Sci-Fi\n",
    "    (47423, 4.0), # 47423,Half Nelson (2006),Drama\n",
    "    (4306, 5.0), # 4306,Shrek (2001),Adventure|Animation|Children|Comedy|Fantasy|Romance\n",
    "    (8360, 5.0), # 8360,Shrek 2 (2004),Adventure|Animation|Children|Comedy|Musical|Romance\n",
    "    (53121, 5.0), # 53121,Shrek the Third (2007),Adventure|Animation|Children|Comedy|Fantasy\n",
    "    (541, 5.0), # 541,Blade Runner (1982),Action|Sci-Fi|Thriller\n",
    "    (122886,2.0), # 122886,Star Wars: Episode VII - The Force Awakens (2015),Action|Adventure|Fantasy|Sci-Fi|IMAX\n",
    "    (5444, 5.0), # 5444,Lilo & Stitch (2002),Adventure|Animation|Children|Sci-Fi\n",
    "    (171749, 4.0), # 171749,Death Note: Desu nôto (2006–2007),(no genres listed)\n",
    "    (47, 4.5), # 47,Seven (a.k.a. Se7en) (1995),Mystery|Thriller\n",
    "    (1201, 5.0), # 1201,\"Good, the Bad and the Ugly, The (Buono, il brutto, il cattivo, Il) (1966)\",Action|Adventure|Western\n",
    "    (2951, 5.0), # 2951,\"Fistful of Dollars, A (Per un pugno di dollari) (1964)\",Action|Western\n",
    "    (64614, 5.0), # 64614,Gran Torino (2008),Crime|Drama\n",
    "    (72737, 5.0), # 72737,\"Princess and the Frog, The (2009)\",Animation|Children|Fantasy|Musical|Romance\n",
    "    (101525, 3.5), # 101525,\"Place Beyond the Pines, The (2012)\",Crime|Drama\n",
    "    (31658, 5.0), # 31658,Howl's Moving Castle (Hauru no ugoku shiro) (2004),Adventure|Animation|Fantasy|Romance\n",
    "]\n",
    "\n",
    "movielens_train = MovielensDataset(DATASET_SOURCE, train=True, new_user_ratings=RATINGS)\n",
    "movielens_test  = MovielensDataset(DATASET_SOURCE, train=False)\n",
    "\n",
    "train_loader = DataLoader(movielens_train, BATCH_SIZE, True)\n",
    "test_loader = DataLoader(movielens_test, BATCH_SIZE, True)\n",
    "\n",
    "for batch in train_loader:\n",
    "    for k, v in batch.items():\n",
    "        print(k, v.shape)\n",
    "    break"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user torch.Size([200, 1])\n",
      "movie torch.Size([200, 1])\n",
      "rating torch.Size([200, 1])\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T00:31:30.437783Z",
     "start_time": "2024-12-06T00:31:30.420113Z"
    }
   },
   "source": [
    "# Функции для обучения из прошлой лабы, с учётом юзеров и айтемов\n",
    "\n",
    "def train_iteration(model, data_loader, loss_function, optimizer):\n",
    "    model.train()\n",
    "    train_size = len(data_loader.dataset)\n",
    "    for idx, batch in enumerate(data_loader):\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        pred = model(batch)\n",
    "        loss = loss_function(pred, batch['rating'])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        if idx % 100 == 0:\n",
    "            loss, current = loss.item(), (idx + 1) * BATCH_SIZE\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{train_size:>5d}]\")\n",
    "\n",
    "def test(model, data_loader, loss_function):\n",
    "    model.eval()\n",
    "    num_batches = len(data_loader)\n",
    "    loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader:\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            pred = model(batch)\n",
    "            loss += loss_function(pred, batch['rating']).item()\n",
    "\n",
    "    loss /= num_batches\n",
    "    print(f\"Avg loss: {loss:>8f} \\n\")\n",
    "\n",
    "\n",
    "def train(epochs, model, loss_function, optimizer):\n",
    "    for t in tqdm(range(epochs)):\n",
    "        print(f\"== Epoch {t + 1} ==\")\n",
    "        train_iteration(model, train_loader, loss_function, optimizer)\n",
    "        test(model, test_loader, loss_function)\n"
   ],
   "outputs": [],
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T00:31:30.748239Z",
     "start_time": "2024-12-06T00:31:30.438649Z"
    }
   },
   "source": [
    "class DeepFM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.user_embeddings = nn.Embedding(1000, 32)\n",
    "        self.movie_embeddings = nn.Embedding(10000, 32)\n",
    "\n",
    "        self.deep_layers = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),  # for regularization\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(32, 16),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.final_layer = nn.Linear(32 + 16, 1)  # adjusted input size\n",
    "\n",
    "    def forward(self, batch):\n",
    "        movie_emb = self.user_embeddings(batch['user']).squeeze(1)\n",
    "        user_emb = self.movie_embeddings(batch['movie']).squeeze(1)\n",
    "\n",
    "        fm = movie_emb * user_emb\n",
    "\n",
    "        deep = torch.cat([movie_emb, user_emb], 1)\n",
    "        deep = self.deep_layers(deep)\n",
    "\n",
    "        v = torch.cat([fm, deep], 1)\n",
    "        v = self.final_layer(v)\n",
    "        # делаем сигмоиду на выходе и масштабируем к оценкам от 0 до 5\n",
    "        return torch.sigmoid(v) * 5\n",
    "\n",
    "EPOCHS_COUNT = 10\n",
    "LEARNING_RATE = 1e-3\n",
    "\n",
    "deep_mf_model = DeepFM().to(device)\n",
    "deep_mf_loss = nn.MSELoss()\n",
    "deep_mf_optimizer = torch.optim.Adam(deep_mf_model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "train(EPOCHS_COUNT, deep_mf_model, deep_mf_loss, deep_mf_optimizer)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Epoch 1 ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[26], line 42\u001B[0m\n\u001B[1;32m     39\u001B[0m deep_mf_loss \u001B[38;5;241m=\u001B[39m nn\u001B[38;5;241m.\u001B[39mMSELoss()\n\u001B[1;32m     40\u001B[0m deep_mf_optimizer \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39moptim\u001B[38;5;241m.\u001B[39mAdam(deep_mf_model\u001B[38;5;241m.\u001B[39mparameters(), lr\u001B[38;5;241m=\u001B[39mLEARNING_RATE)\n\u001B[0;32m---> 42\u001B[0m \u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mEPOCHS_COUNT\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdeep_mf_model\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdeep_mf_loss\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdeep_mf_optimizer\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[25], line 34\u001B[0m, in \u001B[0;36mtrain\u001B[0;34m(epochs, model, loss_function, optimizer)\u001B[0m\n\u001B[1;32m     32\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m t \u001B[38;5;129;01min\u001B[39;00m tqdm(\u001B[38;5;28mrange\u001B[39m(epochs)):\n\u001B[1;32m     33\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m== Epoch \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mt\u001B[38;5;250m \u001B[39m\u001B[38;5;241m+\u001B[39m\u001B[38;5;250m \u001B[39m\u001B[38;5;241m1\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m ==\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m---> 34\u001B[0m     \u001B[43mtrain_iteration\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mloss_function\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     35\u001B[0m     test(model, test_loader, loss_function)\n",
      "Cell \u001B[0;32mIn[25], line 11\u001B[0m, in \u001B[0;36mtrain_iteration\u001B[0;34m(model, data_loader, loss_function, optimizer)\u001B[0m\n\u001B[1;32m      9\u001B[0m loss \u001B[38;5;241m=\u001B[39m loss_function(pred, batch[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mrating\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[1;32m     10\u001B[0m loss\u001B[38;5;241m.\u001B[39mbackward()\n\u001B[0;32m---> 11\u001B[0m \u001B[43moptimizer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstep\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     12\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[1;32m     13\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m idx \u001B[38;5;241m%\u001B[39m \u001B[38;5;241m100\u001B[39m \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n",
      "File \u001B[0;32m~/Source/edu/ai/venv/lib/python3.12/site-packages/torch/optim/optimizer.py:487\u001B[0m, in \u001B[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    482\u001B[0m         \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    483\u001B[0m             \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\n\u001B[1;32m    484\u001B[0m                 \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfunc\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mresult\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    485\u001B[0m             )\n\u001B[0;32m--> 487\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    488\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_optimizer_step_code()\n\u001B[1;32m    490\u001B[0m \u001B[38;5;66;03m# call optimizer step post hooks\u001B[39;00m\n",
      "File \u001B[0;32m~/Source/edu/ai/venv/lib/python3.12/site-packages/torch/optim/optimizer.py:91\u001B[0m, in \u001B[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m     89\u001B[0m     torch\u001B[38;5;241m.\u001B[39mset_grad_enabled(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdefaults[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdifferentiable\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n\u001B[1;32m     90\u001B[0m     torch\u001B[38;5;241m.\u001B[39m_dynamo\u001B[38;5;241m.\u001B[39mgraph_break()\n\u001B[0;32m---> 91\u001B[0m     ret \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     92\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m     93\u001B[0m     torch\u001B[38;5;241m.\u001B[39m_dynamo\u001B[38;5;241m.\u001B[39mgraph_break()\n",
      "File \u001B[0;32m~/Source/edu/ai/venv/lib/python3.12/site-packages/torch/optim/adam.py:197\u001B[0m, in \u001B[0;36mAdam.step\u001B[0;34m(self, closure)\u001B[0m\n\u001B[1;32m    189\u001B[0m \u001B[38;5;129m@_use_grad_for_differentiable\u001B[39m\n\u001B[1;32m    190\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mstep\u001B[39m(\u001B[38;5;28mself\u001B[39m, closure\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[1;32m    191\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Perform a single optimization step.\u001B[39;00m\n\u001B[1;32m    192\u001B[0m \n\u001B[1;32m    193\u001B[0m \u001B[38;5;124;03m    Args:\u001B[39;00m\n\u001B[1;32m    194\u001B[0m \u001B[38;5;124;03m        closure (Callable, optional): A closure that reevaluates the model\u001B[39;00m\n\u001B[1;32m    195\u001B[0m \u001B[38;5;124;03m            and returns the loss.\u001B[39;00m\n\u001B[1;32m    196\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 197\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_cuda_graph_capture_health_check\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    199\u001B[0m     loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    200\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m closure \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[0;32m~/Source/edu/ai/venv/lib/python3.12/site-packages/torch/optim/optimizer.py:430\u001B[0m, in \u001B[0;36mOptimizer._cuda_graph_capture_health_check\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    414\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_cuda_graph_capture_health_check\u001B[39m(\u001B[38;5;28mself\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    415\u001B[0m     \u001B[38;5;66;03m# Note [torch.compile x capturable]\u001B[39;00m\n\u001B[1;32m    416\u001B[0m     \u001B[38;5;66;03m# If we are compiling, we try to take the capturable path automatically by\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    423\u001B[0m     \u001B[38;5;66;03m# Thus, when compiling, inductor will determine if cudagraphs\u001B[39;00m\n\u001B[1;32m    424\u001B[0m     \u001B[38;5;66;03m# can be enabled based on whether there is input mutation or CPU tensors.\u001B[39;00m\n\u001B[1;32m    425\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[1;32m    426\u001B[0m         \u001B[38;5;129;01mnot\u001B[39;00m is_compiling()\n\u001B[1;32m    427\u001B[0m         \u001B[38;5;129;01mand\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mbackends\u001B[38;5;241m.\u001B[39mcuda\u001B[38;5;241m.\u001B[39mis_built()\n\u001B[1;32m    428\u001B[0m         \u001B[38;5;129;01mand\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mcuda\u001B[38;5;241m.\u001B[39mis_available()\n\u001B[1;32m    429\u001B[0m     ):\n\u001B[0;32m--> 430\u001B[0m         capturing \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcuda\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mis_current_stream_capturing\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    432\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m capturing \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mall\u001B[39m(\n\u001B[1;32m    433\u001B[0m             group[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcapturable\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;28;01mfor\u001B[39;00m group \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mparam_groups\n\u001B[1;32m    434\u001B[0m         ):\n\u001B[1;32m    435\u001B[0m             \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\n\u001B[1;32m    436\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAttempting CUDA graph capture of step() for an instance of \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    437\u001B[0m                 \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\n\u001B[1;32m    438\u001B[0m                 \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m but param_groups\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m capturable is False.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    439\u001B[0m             )\n",
      "File \u001B[0;32m~/Source/edu/ai/venv/lib/python3.12/site-packages/torch/cuda/graphs.py:30\u001B[0m, in \u001B[0;36mis_current_stream_capturing\u001B[0;34m()\u001B[0m\n\u001B[1;32m     25\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mis_current_stream_capturing\u001B[39m():\n\u001B[1;32m     26\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"Return True if CUDA graph capture is underway on the current CUDA stream, False otherwise.\u001B[39;00m\n\u001B[1;32m     27\u001B[0m \n\u001B[1;32m     28\u001B[0m \u001B[38;5;124;03m    If a CUDA context does not exist on the current device, returns False without initializing the context.\u001B[39;00m\n\u001B[1;32m     29\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m---> 30\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_cuda_isCurrentStreamCapturing\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mRuntimeError\u001B[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "SUGGESTIONS_COUNT = 10\n",
    "\n",
    "print(\"Movie Recommendations for me:\")\n",
    "new_user_id = movielens_train.ratings['userId'].max()\n",
    "suggestions = suggest_movies(deep_mf_model, new_user_id, movielens_train.movies, suggestions_count=10)\n",
    "suggestions"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
