{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Лаб-3. Рекомендательные системы"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-05T23:40:30.596892Z",
     "start_time": "2024-12-05T23:40:30.593839Z"
    }
   },
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "# Выбираем девайс\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f'Device: {device}')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-05T23:40:30.669954Z",
     "start_time": "2024-12-05T23:40:30.618849Z"
    }
   },
   "source": [
    "# Для загрузки датасета напишем свою реализацию класса Dataset\n",
    "class MovielensDataset(Dataset):\n",
    "    r\"\"\"seed должен быть одинаковым для обучающей и тренировочной выборки\"\"\"\n",
    "    def __init__(self, source, train=True, seed=1, new_user_ratings=None):\n",
    "        ratings      = pd.read_csv(rf\"{source}/ratings.csv\")\n",
    "        self.movies  = pd.read_csv(rf\"{source}/movies.csv\")\n",
    "\n",
    "        # Преобразовываем Id фильмов в индексы в таблице movies\n",
    "        x = self.movies.loc[:,['movieId']]\n",
    "        x['movieId'], x.index = x.index, x['movieId'].values\n",
    "        ratings['movieId'] = ratings['movieId'].map(x.to_dict()['movieId'])\n",
    "\n",
    "        if new_user_ratings:\n",
    "            new_user_id = ratings['userId'].max() + 1\n",
    "            new_ratings = pd.DataFrame([\n",
    "                {\n",
    "                    'userId': new_user_id,\n",
    "                    'movieId': movie_idx,\n",
    "                    'rating': rating\n",
    "                } for movie_idx, rating in new_user_ratings\n",
    "            ])\n",
    "            ratings = pd.concat([ratings, new_ratings], ignore_index=True)\n",
    "\n",
    "        # делим датасет 80% на 20%\n",
    "        train_data = ratings.sample(frac=0.8, random_state=seed)\n",
    "        test_data  = ratings.drop(train_data.index)\n",
    "\n",
    "        self.ratings = train_data if train else test_data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ratings)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.ratings.iloc[idx]\n",
    "        return {\n",
    "            \"user\": torch.LongTensor([sample['userId']]),\n",
    "            \"movie\": torch.LongTensor([sample['movieId']]),\n",
    "            \"rating\": torch.FloatTensor([sample['rating']])\n",
    "        }\n",
    "\n",
    "def generate_random_ratings(num_movies, num_ratings=20):\n",
    "    random_movies = random.sample(range(num_movies), num_ratings)\n",
    "    ratings = [(movie_idx, random.uniform(1, 5)) for movie_idx in random_movies]\n",
    "    return ratings\n",
    "\n",
    "def suggest_movies(model, user_id, movies_df, suggestions_count=10):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        all_movie_ids = torch.arange(len(movies_df), dtype=torch.long).to(device)\n",
    "        user_tensor = torch.LongTensor([user_id] * len(all_movie_ids)).to(device)\n",
    "        predictions = model({\"user\": user_tensor.unsqueeze(1), \"movie\": all_movie_ids.unsqueeze(1)})\n",
    "        predictions = predictions.squeeze(1)\n",
    "        recommended_ids = predictions.argsort(descending=True)[:suggestions_count]\n",
    "        return movies_df.iloc[recommended_ids.cpu().numpy()]"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-05T23:40:30.834369Z",
     "start_time": "2024-12-05T23:40:30.670720Z"
    }
   },
   "source": [
    "BATCH_SIZE = 200\n",
    "DATASET_SOURCE = r'./data'\n",
    "MOCK_RATINGS_COUNT = 20\n",
    "\n",
    "mock_ratings = generate_random_ratings(MOCK_RATINGS_COUNT)\n",
    "\n",
    "movielens_train = MovielensDataset(DATASET_SOURCE, train=True, new_user_ratings=mock_ratings)\n",
    "movielens_test  = MovielensDataset(DATASET_SOURCE, train=False)\n",
    "\n",
    "train_loader = DataLoader(movielens_train, BATCH_SIZE, True)\n",
    "test_loader = DataLoader(movielens_test, BATCH_SIZE, True)\n",
    "\n",
    "for batch in train_loader:\n",
    "    for k, v in batch.items():\n",
    "        print(k, v.shape)\n",
    "    break"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user torch.Size([200, 1])\n",
      "movie torch.Size([200, 1])\n",
      "rating torch.Size([200, 1])\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-05T23:40:30.840845Z",
     "start_time": "2024-12-05T23:40:30.835291Z"
    }
   },
   "source": [
    "# Функции для обучения из прошлой лабы, с учётом юзеров и айтемов\n",
    "\n",
    "def train_iteration(model, data_loader, loss_function, optimizer):\n",
    "    model.train()\n",
    "    train_size = len(data_loader.dataset)\n",
    "    for idx, batch in enumerate(data_loader):\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        pred = model(batch)\n",
    "        loss = loss_function(pred, batch['rating'])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        if idx % 100 == 0:\n",
    "            loss, current = loss.item(), (idx + 1) * BATCH_SIZE\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{train_size:>5d}]\")\n",
    "\n",
    "def test(model, data_loader, loss_function):\n",
    "    model.eval()\n",
    "    num_batches = len(data_loader)\n",
    "    loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader:\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            pred = model(batch)\n",
    "            loss += loss_function(pred, batch['rating']).item()\n",
    "\n",
    "    loss /= num_batches\n",
    "    print(f\"Avg loss: {loss:>8f} \\n\")\n",
    "\n",
    "\n",
    "def train(epochs, model, loss_function, optimizer):\n",
    "    for t in tqdm(range(epochs)):\n",
    "        print(f\"== Epoch {t + 1} ==\")\n",
    "        train_iteration(model, train_loader, loss_function, optimizer)\n",
    "        test(model, test_loader, loss_function)\n"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-05T23:41:16.262690Z",
     "start_time": "2024-12-05T23:40:30.841893Z"
    }
   },
   "source": [
    "class DeepFM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.user_embeddings = nn.Embedding(1000, 32)\n",
    "        self.movie_embeddings = nn.Embedding(10000, 32)\n",
    "\n",
    "        self.deep_layers = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),  # for regularization\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(32, 16),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.final_layer = nn.Linear(32 + 16, 1)  # adjusted input size\n",
    "\n",
    "    def forward(self, batch):\n",
    "        movie_emb = self.user_embeddings(batch['user']).squeeze(1)\n",
    "        user_emb = self.movie_embeddings(batch['movie']).squeeze(1)\n",
    "\n",
    "        fm = movie_emb * user_emb\n",
    "\n",
    "        deep = torch.cat([movie_emb, user_emb], 1)\n",
    "        deep = self.deep_layers(deep)\n",
    "\n",
    "        v = torch.cat([fm, deep], 1)\n",
    "        v = self.final_layer(v)\n",
    "        # делаем сигмоиду на выходе и масштабируем к оценкам от 0 до 5\n",
    "        return torch.sigmoid(v) * 5\n",
    "\n",
    "EPOCHS_COUNT = 10\n",
    "LEARNING_RATE = 1e-3\n",
    "\n",
    "deep_mf_model = DeepFM().to(device)\n",
    "deep_mf_loss = nn.MSELoss()\n",
    "deep_mf_optimizer = torch.optim.Adam(deep_mf_model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "train(EPOCHS_COUNT, deep_mf_model, deep_mf_loss, deep_mf_optimizer)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Epoch 1 ==\n",
      "loss: 2.227392  [  200/80685]\n",
      "loss: 1.231403  [20200/80685]\n",
      "loss: 0.996539  [40200/80685]\n",
      "loss: 0.973332  [60200/80685]\n",
      "loss: 0.966226  [80200/80685]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [00:04<00:44,  4.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg loss: 0.992332 \n",
      "\n",
      "== Epoch 2 ==\n",
      "loss: 0.923173  [  200/80685]\n",
      "loss: 1.124682  [20200/80685]\n",
      "loss: 0.855638  [40200/80685]\n",
      "loss: 0.977245  [60200/80685]\n",
      "loss: 0.820266  [80200/80685]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [00:09<00:36,  4.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg loss: 0.931574 \n",
      "\n",
      "== Epoch 3 ==\n",
      "loss: 0.908505  [  200/80685]\n",
      "loss: 0.892067  [20200/80685]\n",
      "loss: 0.946081  [40200/80685]\n",
      "loss: 0.880783  [60200/80685]\n",
      "loss: 0.985706  [80200/80685]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [00:13<00:32,  4.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg loss: 0.888152 \n",
      "\n",
      "== Epoch 4 ==\n",
      "loss: 0.886115  [  200/80685]\n",
      "loss: 0.970725  [20200/80685]\n",
      "loss: 0.876778  [40200/80685]\n",
      "loss: 0.927692  [60200/80685]\n",
      "loss: 0.885454  [80200/80685]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [00:18<00:27,  4.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg loss: 0.860449 \n",
      "\n",
      "== Epoch 5 ==\n",
      "loss: 0.692394  [  200/80685]\n",
      "loss: 0.851198  [20200/80685]\n",
      "loss: 0.766948  [40200/80685]\n",
      "loss: 0.843819  [60200/80685]\n",
      "loss: 0.770755  [80200/80685]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [00:22<00:22,  4.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg loss: 0.836700 \n",
      "\n",
      "== Epoch 6 ==\n",
      "loss: 0.861831  [  200/80685]\n",
      "loss: 0.730927  [20200/80685]\n",
      "loss: 0.783963  [40200/80685]\n",
      "loss: 0.954893  [60200/80685]\n",
      "loss: 0.690941  [80200/80685]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [00:27<00:17,  4.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg loss: 0.824368 \n",
      "\n",
      "== Epoch 7 ==\n",
      "loss: 0.719483  [  200/80685]\n",
      "loss: 0.688799  [20200/80685]\n",
      "loss: 0.590382  [40200/80685]\n",
      "loss: 0.715703  [60200/80685]\n",
      "loss: 0.650757  [80200/80685]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [00:31<00:13,  4.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg loss: 0.809641 \n",
      "\n",
      "== Epoch 8 ==\n",
      "loss: 0.771045  [  200/80685]\n",
      "loss: 0.678787  [20200/80685]\n",
      "loss: 0.879492  [40200/80685]\n",
      "loss: 0.719320  [60200/80685]\n",
      "loss: 0.670103  [80200/80685]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [00:35<00:08,  4.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg loss: 0.797578 \n",
      "\n",
      "== Epoch 9 ==\n",
      "loss: 0.773797  [  200/80685]\n",
      "loss: 0.774033  [20200/80685]\n",
      "loss: 0.957728  [40200/80685]\n",
      "loss: 0.616723  [60200/80685]\n",
      "loss: 0.696504  [80200/80685]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [00:40<00:04,  4.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg loss: 0.792528 \n",
      "\n",
      "== Epoch 10 ==\n",
      "loss: 0.715858  [  200/80685]\n",
      "loss: 0.881447  [20200/80685]\n",
      "loss: 0.697860  [40200/80685]\n",
      "loss: 0.682960  [60200/80685]\n",
      "loss: 0.595806  [80200/80685]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:44<00:00,  4.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg loss: 0.785119 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-05T23:44:07.481261Z",
     "start_time": "2024-12-05T23:44:07.467864Z"
    }
   },
   "cell_type": "code",
   "source": [
    "SUGGESTIONS_COUNT = 10\n",
    "\n",
    "print(\"Movie Recommendations for me:\")\n",
    "new_user_id = movielens_train.ratings['userId'].max()\n",
    "suggestions = suggest_movies(deep_mf_model, new_user_id, movielens_train.movies, suggestions_count=10)\n",
    "suggestions"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movie Recommendations for me:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "      movieId                                              title  \\\n",
       "9575   174551                                   Obsession (1965)   \n",
       "6051    40491  Match Factory Girl, The (Tulitikkutehtaan tytt...   \n",
       "9514   171495                                             Cosmos   \n",
       "8706   124273                 Kevin Smith: Too Fat For 40 (2010)   \n",
       "277       318                   Shawshank Redemption, The (1994)   \n",
       "4413     6514                              Ring of Terror (1962)   \n",
       "8763   128592                           The Boy Next Door (2015)   \n",
       "2740     3678                Man with the Golden Arm, The (1955)   \n",
       "461       527                            Schindler's List (1993)   \n",
       "3043     4077  With a Friend Like Harry... (Harry, un ami qui...   \n",
       "\n",
       "                  genres  \n",
       "9575              Comedy  \n",
       "6051        Comedy|Drama  \n",
       "9514  (no genres listed)  \n",
       "8706              Comedy  \n",
       "277          Crime|Drama  \n",
       "4413              Horror  \n",
       "8763    Mystery|Thriller  \n",
       "2740               Drama  \n",
       "461            Drama|War  \n",
       "3043      Drama|Thriller  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9575</th>\n",
       "      <td>174551</td>\n",
       "      <td>Obsession (1965)</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6051</th>\n",
       "      <td>40491</td>\n",
       "      <td>Match Factory Girl, The (Tulitikkutehtaan tytt...</td>\n",
       "      <td>Comedy|Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9514</th>\n",
       "      <td>171495</td>\n",
       "      <td>Cosmos</td>\n",
       "      <td>(no genres listed)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8706</th>\n",
       "      <td>124273</td>\n",
       "      <td>Kevin Smith: Too Fat For 40 (2010)</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>318</td>\n",
       "      <td>Shawshank Redemption, The (1994)</td>\n",
       "      <td>Crime|Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4413</th>\n",
       "      <td>6514</td>\n",
       "      <td>Ring of Terror (1962)</td>\n",
       "      <td>Horror</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8763</th>\n",
       "      <td>128592</td>\n",
       "      <td>The Boy Next Door (2015)</td>\n",
       "      <td>Mystery|Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2740</th>\n",
       "      <td>3678</td>\n",
       "      <td>Man with the Golden Arm, The (1955)</td>\n",
       "      <td>Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>527</td>\n",
       "      <td>Schindler's List (1993)</td>\n",
       "      <td>Drama|War</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3043</th>\n",
       "      <td>4077</td>\n",
       "      <td>With a Friend Like Harry... (Harry, un ami qui...</td>\n",
       "      <td>Drama|Thriller</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
