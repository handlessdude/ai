{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Лаб-4. Рекомендации для коротких сессий"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-27T17:33:08.153803Z",
     "start_time": "2024-12-27T17:33:08.151908Z"
    }
   },
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "from tqdm import tqdm"
   ],
   "outputs": [],
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-27T17:33:08.211538Z",
     "start_time": "2024-12-27T17:33:08.160019Z"
    }
   },
   "source": [
    "IS_CUDA_USED = False\n",
    "device = \"cuda\" if torch.cuda.is_available() and IS_CUDA_USED else \"cpu\"\n",
    "print(f'Device: {device}')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-27T17:33:08.287062Z",
     "start_time": "2024-12-27T17:33:08.212351Z"
    }
   },
   "source": [
    "EMBEDDING_SIZE = 64\n",
    "\n",
    "HIDDEN_SIZE = 64\n",
    "\n",
    "ITEM_SIZE = 15316\n",
    "\n",
    "class GRU4Rec(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        embedding_size = EMBEDDING_SIZE\n",
    "        self.hidden_size = HIDDEN_SIZE\n",
    "        item_size = ITEM_SIZE\n",
    "        \n",
    "        self.num_layers = 1\n",
    "        self.state = torch.zeros([self.num_layers, batch_size, self.hidden_size])\n",
    "        self.embedding = nn.Embedding(item_size, embedding_size)\n",
    "        self.gru = nn.GRU(embedding_size, self.hidden_size, num_layers=self.num_layers, batch_first=True)\n",
    "        self.output_layer = nn.Linear(self.hidden_size, item_size)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    # Перегрузка to чтобы состояние тоже перевести на девайс\n",
    "    def to(self, device):\n",
    "        self.state = self.state.to(device)\n",
    "        return super().to(device)\n",
    "\n",
    "    # Обнуляем состояние для новых сессий\n",
    "    def update_state(self, mask=None):\n",
    "        self.state.detach_()\n",
    "        if mask is None:\n",
    "            self.state = torch.zeros(\n",
    "                self.num_layers, batch_size, self.hidden_size, device=device\n",
    "            )\n",
    "        else:\n",
    "            self.state[:, mask, :] = 0\n",
    "\n",
    "    def forward(self, input):\n",
    "        self.update_state(mask=None)\n",
    "        v = input.unsqueeze(1)\n",
    "        v = self.embedding(v)\n",
    "        v, self.state = self.gru(v, self.state) # (batch_size, 1, hidden_size)\n",
    "        hidden = v.squeeze(1) # (batch_size, hidden_size)\n",
    "        v = self.dropout(hidden)\n",
    "        v = self.output_layer(v)\n",
    "        return v"
   ],
   "outputs": [],
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-27T17:33:08.370182Z",
     "start_time": "2024-12-27T17:33:08.287645Z"
    }
   },
   "source": [
    "# Тренировка происходит и тестирование\n",
    "\n",
    "def train_iteration(model, data_loader, loss_function, optimizer):\n",
    "    model.train()\n",
    "\n",
    "    for batch, (x, y, m) in enumerate(data_loader):\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        # Не забываем обнулить состояние\n",
    "        model.update_state(m)\n",
    "\n",
    "        pred = model(x)\n",
    "        loss = loss_function(pred, y)\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch % 1000 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(x)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}]\")\n",
    "\n",
    "def test(model, data_loader, loss_function):\n",
    "    model.eval()\n",
    "\n",
    "    loss, correct, count = 0, 0 ,0\n",
    "    with torch.no_grad():\n",
    "        for x, y, m in data_loader:\n",
    "            count += 1\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            model.update_state(m)\n",
    "            pred = model(x)\n",
    "            loss += loss_function(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    loss = loss / count\n",
    "    correct /= count * batch_size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {loss:>8f} \\n\")\n",
    "    pass\n",
    "\n",
    "\n",
    "def train(epochs, model, loss_function, optimizer):\n",
    "    for t in tqdm(range(epochs)):\n",
    "        print(f\"== Epoch {t + 1} ==\")\n",
    "        train_iteration(model, train_loader, loss_function, optimizer)\n",
    "        test(model, test_loader, loss_function)"
   ],
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-27T17:33:08.509090Z",
     "start_time": "2024-12-27T17:33:08.371191Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class MovieLensDatasetRaw:\n",
    "    def __init__(self, path):\n",
    "        ratings = pd.read_csv(rf'{path}/ratings.csv')\n",
    "\n",
    "        self.train_data = ratings.sample(frac=0.8, random_state=1)\n",
    "        self.test_data  = ratings.drop(self.train_data.index)\n",
    "        self.train_data.reset_index(drop=True, inplace=True)\n",
    "        self.test_data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        all_data = pd.concat([self.train_data, self.test_data])\n",
    "        unique_items = all_data['movieId'].unique()\n",
    "        item_to_idx = pd.Series(data=np.arange(len(unique_items)), index=unique_items)\n",
    "        item_map = pd.DataFrame({'movieId': unique_items, 'movieIndex': item_to_idx[unique_items].values})\n",
    "        self.train_data = pd.merge(self.train_data, item_map, on='movieId', how='inner')\n",
    "        self.test_data  = pd.merge(self.test_data,  item_map, on='movieId', how='inner')\n",
    "\n",
    "        # Сортируем датасет так, чтобы все сессии оказались рядом, а клики внутри сессии упорядочились по времени\n",
    "        self.train_data.sort_values(['userId', 'timestamp'], inplace=True)\n",
    "        self.test_data.sort_values(['userId', 'timestamp'], inplace=True)\n",
    "\n",
    "dataset = MovieLensDatasetRaw(\"MovieLens\")"
   ],
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-27T17:33:08.556551Z",
     "start_time": "2024-12-27T17:33:08.509733Z"
    }
   },
   "cell_type": "code",
   "source": "dataset.train_data",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "       userId  movieId  rating   timestamp  movieIndex\n",
       "76507       1      804     4.0   964980499        4045\n",
       "15408       1     2826     4.0   964980523        1915\n",
       "18151       1     2628     4.0   964980523         383\n",
       "46045       1     3578     5.0   964980668         302\n",
       "64921       1     3617     4.0   964980683        1085\n",
       "...       ...      ...     ...         ...         ...\n",
       "15699     610   101739     3.5  1495959269        4584\n",
       "80395     610       70     4.0  1495959282         887\n",
       "48900     610      328     3.5  1495959299         222\n",
       "30316     610     2459     3.5  1495959405        2238\n",
       "49148     610     3917     4.0  1495959411        1878\n",
       "\n",
       "[80669 rows x 5 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>movieIndex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>76507</th>\n",
       "      <td>1</td>\n",
       "      <td>804</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964980499</td>\n",
       "      <td>4045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15408</th>\n",
       "      <td>1</td>\n",
       "      <td>2826</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964980523</td>\n",
       "      <td>1915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18151</th>\n",
       "      <td>1</td>\n",
       "      <td>2628</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964980523</td>\n",
       "      <td>383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46045</th>\n",
       "      <td>1</td>\n",
       "      <td>3578</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964980668</td>\n",
       "      <td>302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64921</th>\n",
       "      <td>1</td>\n",
       "      <td>3617</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964980683</td>\n",
       "      <td>1085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15699</th>\n",
       "      <td>610</td>\n",
       "      <td>101739</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1495959269</td>\n",
       "      <td>4584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80395</th>\n",
       "      <td>610</td>\n",
       "      <td>70</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1495959282</td>\n",
       "      <td>887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48900</th>\n",
       "      <td>610</td>\n",
       "      <td>328</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1495959299</td>\n",
       "      <td>222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30316</th>\n",
       "      <td>610</td>\n",
       "      <td>2459</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1495959405</td>\n",
       "      <td>2238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49148</th>\n",
       "      <td>610</td>\n",
       "      <td>3917</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1495959411</td>\n",
       "      <td>1878</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80669 rows × 5 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-27T17:33:08.621904Z",
     "start_time": "2024-12-27T17:33:08.557217Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\n",
    "    'Количество уникальных фильмов',\n",
    "    pd.concat([dataset.train_data, dataset.test_data])['movieId'].nunique(),\n",
    "    '=',\n",
    "    pd.concat([dataset.train_data, dataset.test_data])['movieIndex'].max() + 1\n",
    ")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество уникальных фильмов 9724 = 9724\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-27T17:33:08.731548Z",
     "start_time": "2024-12-27T17:33:08.622569Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class MovieLensLoader():\n",
    "    def __init__(self, data, batch_size, shuffle=False):\n",
    "        self.data = data\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.session_count = data['userId'].nunique()\n",
    "\n",
    "        # Делаем массив с индексами начала и конца каждой сессии\n",
    "        session_sizes = np.array(data.groupby('userId').size().cumsum())\n",
    "        self.offsets = np.append([0], session_sizes)\n",
    "\n",
    "    def __iter__(self):\n",
    "        session_order = np.arange(self.session_count)\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(session_order)\n",
    "\n",
    "        # Заводим список активных сессий, размером с батч\n",
    "        active_sessions = np.arange(self.batch_size)\n",
    "        next_session = self.batch_size # индекс следующей сессии\n",
    "        start = self.offsets[session_order[active_sessions]]   # индексы начал активных сессий\n",
    "        end = self.offsets[session_order[active_sessions] + 1] # индексы концов активных сессий\n",
    "\n",
    "        closed_mask = list(active_sessions) # список сессий, которые открываются на текущей итерации\n",
    "        while True:\n",
    "            min_len = (end - start).min() # Количество итераций, которые мы можем пройти, пока не закончится какая-то сессия\n",
    "            idx_target = self.data['movieIndex'].values[start]\n",
    "\n",
    "            # Итерируем по сессиям до тех пор, пока какая-то не закончится\n",
    "            for i in range(min_len - 1):\n",
    "                idx_input = idx_target\n",
    "                idx_target = self.data['movieIndex'].values[start + i + 1]\n",
    "                input = torch.LongTensor(idx_input)\n",
    "                target = torch.LongTensor(idx_target)\n",
    "                yield input, target, closed_mask # маску мы будем использовать чтобы обнулять новые сессии\n",
    "                closed_mask = []\n",
    "\n",
    "            start = start + (min_len - 1)\n",
    "\n",
    "            # Пробегаемся по сессиям, которые должны быть завершены\n",
    "            closed_mask = np.arange(len(active_sessions))[(end - start) <= 1]\n",
    "            for idx in closed_mask:\n",
    "                # Если новых сессий нет, просто завершаемся\n",
    "                if next_session >= len(self.offsets) - 1:\n",
    "                    return\n",
    "                # Обновляем значения для новой сессии\n",
    "                active_sessions[idx] = next_session\n",
    "                start[idx] = self.offsets[session_order[next_session]]\n",
    "                end[idx]   = self.offsets[session_order[next_session] + 1]\n",
    "                next_session += 1\n",
    "\n",
    "batch_size = 10\n",
    "\n",
    "train_loader = MovieLensLoader(dataset.train_data, batch_size, shuffle=True)\n",
    "test_loader  = MovieLensLoader(dataset.test_data, batch_size)"
   ],
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-27T17:36:47.383704Z",
     "start_time": "2024-12-27T17:33:08.732165Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "LEARNING_RATE = 0.001\n",
    "    \n",
    "model = GRU4Rec().to(device)\n",
    "loss = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "    \n",
    "train(10, model, loss, optimizer)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Epoch 1 ==\n",
      "loss: 9.260013  [   10]\n",
      "loss: 7.897375  [10010]\n",
      "loss: 8.394053  [20010]\n",
      "loss: 8.659293  [30010]\n",
      "loss: 8.703279  [40010]\n",
      "loss: 8.545830  [50010]\n",
      "loss: 8.346582  [60010]\n",
      "loss: 7.714411  [70010]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [00:23<03:27, 23.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Accuracy: 0.3%, Avg loss: 8.233953 \n",
      "\n",
      "== Epoch 2 ==\n",
      "loss: 6.773754  [   10]\n",
      "loss: 8.013899  [10010]\n",
      "loss: 8.274556  [20010]\n",
      "loss: 7.744389  [30010]\n",
      "loss: 8.497782  [40010]\n",
      "loss: 8.191710  [50010]\n",
      "loss: 7.830641  [60010]\n",
      "loss: 8.172770  [70010]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [00:45<03:01, 22.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Accuracy: 0.4%, Avg loss: 8.290567 \n",
      "\n",
      "== Epoch 3 ==\n",
      "loss: 6.524554  [   10]\n",
      "loss: 7.892291  [10010]\n",
      "loss: 8.287162  [20010]\n",
      "loss: 8.018817  [30010]\n",
      "loss: 7.835461  [40010]\n",
      "loss: 7.845201  [50010]\n",
      "loss: 8.683865  [60010]\n",
      "loss: 7.685362  [70010]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [01:08<02:39, 22.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Accuracy: 0.4%, Avg loss: 8.368523 \n",
      "\n",
      "== Epoch 4 ==\n",
      "loss: 7.443153  [   10]\n",
      "loss: 8.470109  [10010]\n",
      "loss: 8.630199  [20010]\n",
      "loss: 8.868936  [30010]\n",
      "loss: 7.242331  [40010]\n",
      "loss: 7.936667  [50010]\n",
      "loss: 8.287271  [60010]\n",
      "loss: 7.318661  [70010]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [01:29<02:13, 22.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Accuracy: 0.5%, Avg loss: 8.384969 \n",
      "\n",
      "== Epoch 5 ==\n",
      "loss: 6.068664  [   10]\n",
      "loss: 7.029361  [10010]\n",
      "loss: 8.007060  [20010]\n",
      "loss: 8.840477  [30010]\n",
      "loss: 8.329036  [40010]\n",
      "loss: 8.036967  [50010]\n",
      "loss: 7.782338  [60010]\n",
      "loss: 7.679163  [70010]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [01:51<01:49, 21.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Accuracy: 0.4%, Avg loss: 8.412182 \n",
      "\n",
      "== Epoch 6 ==\n",
      "loss: 6.683441  [   10]\n",
      "loss: 6.529668  [10010]\n",
      "loss: 7.544769  [20010]\n",
      "loss: 7.999526  [30010]\n",
      "loss: 8.679219  [40010]\n",
      "loss: 8.722351  [50010]\n",
      "loss: 8.048471  [60010]\n",
      "loss: 8.301979  [70010]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [02:12<01:27, 21.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Accuracy: 0.4%, Avg loss: 8.419328 \n",
      "\n",
      "== Epoch 7 ==\n",
      "loss: 5.798939  [   10]\n",
      "loss: 7.791919  [10010]\n",
      "loss: 6.831003  [20010]\n",
      "loss: 7.163840  [30010]\n",
      "loss: 8.136454  [40010]\n",
      "loss: 8.264112  [50010]\n",
      "loss: 8.152093  [60010]\n",
      "loss: 7.886177  [70010]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [02:34<01:04, 21.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Accuracy: 0.5%, Avg loss: 8.464479 \n",
      "\n",
      "== Epoch 8 ==\n",
      "loss: 4.729800  [   10]\n",
      "loss: 8.023566  [10010]\n",
      "loss: 7.901656  [20010]\n",
      "loss: 7.061580  [30010]\n",
      "loss: 8.733491  [40010]\n",
      "loss: 7.416753  [50010]\n",
      "loss: 7.926496  [60010]\n",
      "loss: 8.002831  [70010]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [02:55<00:43, 21.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 8.485779 \n",
      "\n",
      "== Epoch 9 ==\n",
      "loss: 5.711685  [   10]\n",
      "loss: 7.916479  [10010]\n",
      "loss: 6.480213  [20010]\n",
      "loss: 8.370117  [30010]\n",
      "loss: 7.667938  [40010]\n",
      "loss: 7.350478  [50010]\n",
      "loss: 7.565291  [60010]\n",
      "loss: 9.156727  [70010]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [03:17<00:21, 21.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Accuracy: 0.5%, Avg loss: 8.509403 \n",
      "\n",
      "== Epoch 10 ==\n",
      "loss: 6.297974  [   10]\n",
      "loss: 7.222162  [10010]\n",
      "loss: 6.498957  [20010]\n",
      "loss: 7.230359  [30010]\n",
      "loss: 7.261389  [40010]\n",
      "loss: 8.384476  [50010]\n",
      "loss: 7.459121  [60010]\n",
      "loss: 8.376918  [70010]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [03:38<00:00, 21.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Accuracy: 0.5%, Avg loss: 8.537762 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 27
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
